{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai2_multimodal_tabtxt_public.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "a7Df2wOIc157",
        "2yXIrPV6XGxr",
        "WyVkVDwNW9f2"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oycxQmEebNuV"
      },
      "source": [
        "## Intro\n",
        "\n",
        "\n",
        "### Purpose:\n",
        "\n",
        "- To build a tabular + text classification module under the most updated version of fastai (at this point fastai : 2.5.2\n",
        "fastcore : 1.3.26), aiming to be\n",
        "  - easy to use (e.g. fastai API)\n",
        "  - efficent\n",
        "  - stable and ready for production\n",
        "\n",
        "- to extend to regression\n",
        "\n",
        "- To extend to tabular + text + vision\n",
        "\n",
        "\n",
        "\n",
        "### Credits & References:\n",
        "\n",
        "- Zachary Mueller's initiatives https://forums.fast.ai/t/combining-tabular-images-in-fastai2-and-should-work-with-almost-any-other-type/73197\n",
        "\n",
        "- Morgan McGuire's notebook on **Gradient Blending for Multimodal Model**: https://forums.fast.ai/t/gradient-blending-for-multi-modal-models-in-progress/75645/11\n",
        "\n",
        "- Zachary Mueller's explanation on how to construct MixedDL https://www.youtube.com/watch?v=myKgF-d9-N4\n",
        "\n",
        "- tabular+ image+ text https://forums.fast.ai/t/wrote-notebook-to-merge-image-tabular-text-data-in-one-neural-network/43614"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnlWWe21YgQq"
      },
      "source": [
        "## set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-dqstVoYkwe",
        "outputId": "4fad8674-ed22-4594-da75-ca37e83d7a16"
      },
      "source": [
        "from pathlib import Path\n",
        "path=Path('/content/gdrive/My Drive/data/')\n",
        "path"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/gdrive/My Drive/data')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Df2wOIc157"
      },
      "source": [
        "## install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8EjZHRUICHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6b5b1c-ce1d-4eab-e1f2-2add16eac2e7"
      },
      "source": [
        "!pip install fastai wwf bayesian-optimization -q --upgrade\n",
        "#!pip install wwf\n",
        "#!pip install fastai wwf bayesian-optimization -q --upgrade\n",
        "#!pip install \"fastai==2.0.13\" \"fastcore==1.2.5\" \"torch==1.6.0\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 186 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 376 kB 45.7 MB/s \n",
            "\u001b[?25h  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yXIrPV6XGxr"
      },
      "source": [
        "## load packages & define helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYxHk7VnXDMy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4729b6d0-2a77-4eb5-9b7b-99f3fab4b19b"
      },
      "source": [
        "from wwf.utils import *\n",
        "from fastai.tabular.all import *\n",
        "from fastai.text.all import *\n",
        "from fastai.vision.all import *\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "state_versions(['fastai', 'fastcore', 'torch'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/markdown": "\n---\nThis article is also a Jupyter Notebook available to be run from the top down. There\nwill be code snippets that you can then run in any environment.\n\nBelow are the versions of `fastai`, `fastcore`, and `torch` currently running at the time of writing this:\n* `fastai` : 2.5.2 \n* `fastcore` : 1.3.26 \n* `torch` : 1.9.0+cu111 \n---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMr5dGFvXDVD"
      },
      "source": [
        "# helper functions\n",
        "\n",
        "def split_idxs(df, train_size=.9, flag_random_split=False):\n",
        "    \"\"\" split df index into 2 parts: train_idxs and test_idxs \n",
        "    Args:\n",
        "        df: the dataframe of all your data\n",
        "        train_size (float in [0,1], default 0.9)\n",
        "        flag_random_split(bool, default False): do you want random split idxs?\n",
        "    Returns:\n",
        "        (ls_train, ls_test): a 2-tuple of lists for train indices and test indices\n",
        "\n",
        "    Example:\n",
        "        df = pd.DataFrame({'c1':list(range(26)), 'c2':list(string.ascii_lowercase)})\n",
        "        splits = split_idxs(df)\n",
        "        ...\n",
        "        # use splits to build TabularPandas taublar object\n",
        "        to = TabularPandas(df, \n",
        "                   procs=procs,\n",
        "                   cat_names=cat_names,\n",
        "                   cont_names=cont_names,\n",
        "                   y_names=y_names,\n",
        "                   y_block=y_block,\n",
        "                   splits=splits)\n",
        "    \"\"\"\n",
        "    import random\n",
        "    ls = range_of(df)\n",
        "    print(ls)\n",
        "    if flag_random_split:\n",
        "        splits = RandomSplitter()(ls)\n",
        "    else:\n",
        "        ls_train = ls[:int(df.shape[0]*train_size)]\n",
        "        ls_test = ls[int(df.shape[0]*train_size):]\n",
        "        random.shuffle(ls_train)\n",
        "        random.shuffle(ls_test)\n",
        "        splits = (ls_train, ls_test)\n",
        "    return splits \n",
        "\n",
        "def split_train_valid_test(df, train_valid_test=[0.7,0.15, 0.15], target='response_status', random_state=123, sort_split_by_datetime=True):\n",
        "    '''Splits a Pandas Dataframe into training, evaluation and serving sets, stratifying on target column.\n",
        "\n",
        "    Args:\n",
        "            df : pandas dataframe to split\n",
        "            train_valid_test: a list of 3 positive numbers, each being either float or integer\n",
        "            target (string): the name of target column\n",
        "            random_state (int or None): the random seed to shuffle df; if None, do not shuffle df\n",
        "    Returns:\n",
        "            train_df: Training dataframe(i.e. 70% of the entire dataset)\n",
        "            valid_df: Evaluation dataframe (i.e. 15% of the entire dataset) \n",
        "            X_test, y_test: Serving dataframe (i.e. 15% of the entire dataset, label column dropped)\n",
        "            keep_datetime_order (default True): after splitting data into train < validation < serving\n",
        "    Ref:\n",
        "        C2W1_assignment.ipynb using TFDV to visulize, validate and moritor data at scale\n",
        "    '''\n",
        "    if len(train_valid_test)==3 and not any(x < 0 for x in train_valid_test):\n",
        "        tot = sum(train_valid_test)\n",
        "        train_valid_test = [x/tot for x in train_valid_test]\n",
        "    else: \n",
        "        raise ValueError('train_valid_test need to be a list of 3 positive numbers!')\n",
        "\n",
        "    if sort_split_by_datetime:\n",
        "        df.sort_index(inplace=True)\n",
        "        n_train, n_valid, n_serv= [int(df.shape[0]*n) for n in train_valid_test]\n",
        "        print('================Double check the indices of train, valid and test are sorted: =================== ')\n",
        "        print(f'{df.index[:n_train], df.index[n_train:(n_train+n_valid)], df.index[(n_train+n_valid):]}')\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "        train_df, valid_df, X_test, y_test  = df.iloc[:n_train,:], df.iloc[n_train:(n_train+n_valid),:], df.iloc[(n_train+n_valid):,:].drop([target], axis=1),df.iloc[(n_train+n_valid):,:][target] \n",
        "        return train_df, valid_df, X_test, y_test\n",
        "\n",
        "    # downstream dl clf can not accept datetime index, therefore df.reset_index()   \n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    train_df, eval_serv = train_test_split(df, stratify=df[target], test_size = 1 - train_valid_test[0], random_state=random_state)\n",
        "    valid_df, test_df = train_test_split(eval_serv, stratify=eval_serv[target], test_size = train_valid_test[1]/(1 - train_valid_test[0]), random_state=random_state)\n",
        "    \n",
        "    # Serving data emulates the data that would be submitted for predictions, so it should not have the label column.\n",
        "    y_test = test_df[target]\n",
        "    X_test = test_df.drop([target], axis=1)\n",
        "\n",
        "    return train_df, valid_df, X_test, y_test\n",
        "\n",
        "def reset_seed(seed=123):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "#     tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "reset_seed()\n",
        "\n",
        "def get_metrics(y_true, y_pred, txt='validation'):\n",
        "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
        "        y_true = y_true.values\n",
        "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
        "        y_pred = y_pred.values\n",
        "    if y_true.ndim>1:\n",
        "        y_true=y_true.ravel()\n",
        "    if y_pred.ndim>1:\n",
        "        y_pred=y_pred.ravel()\n",
        "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, multilabel_confusion_matrix\n",
        "    accu = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    #mul_confu = multilabel_confusion_matrix(y_true, y_pred, labels=)\n",
        "    print(f\"{txt}-Accuracy: {accu} |{txt}-Precision: {precision}|{txt}-Recall: {recall} |  {txt}-F1: {f1}\")\n",
        "    return {\"accuracy\": accu,\n",
        "            \"precision\": precision,\n",
        "            \"recall\":recall,\n",
        "            \"f1\":f1}\n",
        "\n",
        "def procs_df(df,y_names, cat_names, cont_names, text_names):\n",
        "    \"\"\"process categorical and continuous features of df through the fastai procs [Categorify, FillMissing, Normalize], while keeping text features un-changed \"\"\"\n",
        "    procs = [Categorify, FillMissing, Normalize]\n",
        "    y_block = CategoryBlock() # to specify it's a single-label classificaiton problem\n",
        "    splits = split_idxs(df, train_size=.9, flag_random_split=False)\n",
        "\n",
        "    # to build TabularPandas taublar object\n",
        "    to = TabularPandas(df, \n",
        "                      procs=procs,\n",
        "                      cat_names=cat_names,\n",
        "                      cont_names=cont_names,\n",
        "                      y_names=y_names,\n",
        "                      y_block=y_block,\n",
        "                      splits=splits)\n",
        "    df0 = to.ys.reset_index(drop=True)\n",
        "    df1 = to.xs.reset_index(drop=True)\n",
        "    df2 = df[text_names].reset_index(drop=True)\n",
        "    df3 = pd.concat([df0, df1, df2], axis=1)\n",
        "    df3.index = df.index # restore index info to resulted df\n",
        "    return df3"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyVkVDwNW9f2"
      },
      "source": [
        "## load data\n",
        "\n",
        "Our dataset is the [Womens Clothing E-Commerce Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) dataset from kaggle. It contains reviews written by customers about clothing items as well as whether they recommend the data or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WM_aXiZ1XDYU",
        "outputId": "236d0075-142c-49b7-ef8a-c7123882d1f2"
      },
      "source": [
        "data_file = \"https://raw.githubusercontent.com/wjlgatech/fastai-multimodal/main/data/clothing_review.csv\"\n",
        "df = pd.read_csv(data_file, index_col=0)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23481</th>\n",
              "      <td>1104</td>\n",
              "      <td>34</td>\n",
              "      <td>Great dress for many occasions</td>\n",
              "      <td>I was very happy to snag this dress at such a great price! it's very easy to slip on and has a very flattering cut and color combo.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23482</th>\n",
              "      <td>862</td>\n",
              "      <td>48</td>\n",
              "      <td>Wish it was made of cotton</td>\n",
              "      <td>It reminds me of maternity clothes. soft, stretchy, shiny material. cut is flattering and drapes nicely. i only found one button to close front... looked awkward. nice long sleeves.\\nnot for me but maybe for others. just ok.</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23483</th>\n",
              "      <td>1104</td>\n",
              "      <td>31</td>\n",
              "      <td>Cute, but see through</td>\n",
              "      <td>This fit well, but the top was very see through. this never would have worked for me. i'm glad i was able to try it on in the store and didn't order it online. with different fabric, it would have been great.</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23484</th>\n",
              "      <td>1084</td>\n",
              "      <td>28</td>\n",
              "      <td>Very cute dress, perfect for summer parties and we</td>\n",
              "      <td>I bought this dress for a wedding i have this summer, and it's so cute. unfortunately the fit isn't perfect. the medium fits my waist perfectly, but was way too long and too big in the bust and shoulders. if i wanted to spend the money, i could get it tailored, but i just felt like it might not be worth it. side note - this dress was delivered to me with a nordstrom tag on it and i found it much cheaper there after looking!</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23485</th>\n",
              "      <td>1104</td>\n",
              "      <td>52</td>\n",
              "      <td>Please make more like this one!</td>\n",
              "      <td>This dress in a lovely platinum is feminine and fits perfectly, easy to wear and comfy, too! highly recommend!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23486 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Clothing ID  Age  ... Department Name Class Name\n",
              "0              767   33  ...        Intimate  Intimates\n",
              "1             1080   34  ...         Dresses    Dresses\n",
              "2             1077   60  ...         Dresses    Dresses\n",
              "3             1049   50  ...         Bottoms      Pants\n",
              "4              847   47  ...            Tops    Blouses\n",
              "...            ...  ...  ...             ...        ...\n",
              "23481         1104   34  ...         Dresses    Dresses\n",
              "23482          862   48  ...            Tops      Knits\n",
              "23483         1104   31  ...         Dresses    Dresses\n",
              "23484         1084   28  ...         Dresses    Dresses\n",
              "23485         1104   52  ...         Dresses    Dresses\n",
              "\n",
              "[23486 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKJfjAbYWp3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383b0b84-59d2-4f94-eb7b-3f94e5c47d4b"
      },
      "source": [
        "y_names = 'Recommended IND'\n",
        "text_names =  ['Title', 'Review Text']\n",
        "cat_names = ['Clothing ID', 'Division Name', 'Department Name', 'Class Name']\n",
        "cont_names = ['Rating', 'Age', 'Positive Feedback Count']\n",
        "\n",
        "#double check\n",
        "y_names, text_names, cat_names, cont_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Recommended IND',\n",
              " ['Title', 'Review Text'],\n",
              " ['Clothing ID', 'Division Name', 'Department Name', 'Class Name'],\n",
              " ['Rating', 'Age', 'Positive Feedback Count'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pjFLLm7fSHi",
        "outputId": "e8d55aa1-c4bb-4fbf-cb61-9173683330ce"
      },
      "source": [
        "train_df, valid_df, X_test, y_test = split_train_valid_test(df, train_valid_test=[0.7,0.15, 0.15], target=y_names, random_state=123, sort_split_by_datetime=False)\n",
        "\n",
        "# dbck\n",
        "train_df.shape, valid_df.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16440, 10), (3523, 10), (3523, 9), (3523,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m8-JxJ5feKz"
      },
      "source": [
        "## Build Tabular Classifer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw1Aj7xuqr8D"
      },
      "source": [
        "### Tabular DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4r14CQ2zpef"
      },
      "source": [
        "tab_cols = [y_names]+cat_names+cont_names\n",
        "procs = [Categorify, FillMissing, Normalize]\n",
        "\n",
        "flag_random_split=True\n",
        "if flag_random_split:\n",
        "    splitter = RandomSplitter(seed=42)\n",
        "    splits = splitter(range_of(df))\n",
        "else:\n",
        "    splits = (list(train_df.index), list(valid_df.index))\n",
        "\n",
        "flag_gpu_cpu=False\n",
        "if flag_gpu_cpu:\n",
        "    device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smtTg2sifSKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "871ab7e5-b52b-46bc-c323-2d1103669f3f"
      },
      "source": [
        "to = TabularPandas(df[tab_cols], \n",
        "                   procs, \n",
        "                   cat_names, \n",
        "                   cont_names,\n",
        "                   y_names=y_names, \n",
        "                   y_block=CategoryBlock(),\n",
        "                   splits=splits)\n",
        "dls_tab = to.dataloaders(bs=64) \n",
        "dls_tab.show_batch(max_n=3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Age</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Recommended IND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1059</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "      <td>4.0</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1033</td>\n",
              "      <td>General</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Jeans</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>7.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>862</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>1.0</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1094</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>5.0</td>\n",
              "      <td>63.999999</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>943</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Sweaters</td>\n",
              "      <td>3.0</td>\n",
              "      <td>74.999999</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>877</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>5.0</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1183</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>5.0</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>867</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>5.0</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>868</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>854</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LESG326unfbI"
      },
      "source": [
        "#metrics\n",
        "f1=FBeta(beta=1, average='weighted')\n",
        "precision = Precision(average='weighted')\n",
        "recall = Recall(average='weighted')\n",
        "metrics=[accuracy, precision, recall, f1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiTSjCoU5m9N"
      },
      "source": [
        "### Tabular Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhe4asmInfdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "c8caea01-b83e-4b26-aff5-b2fdb004f62d"
      },
      "source": [
        "learn_tab = tabular_learner(dls=dls_tab, layers=[200,100], metrics=metrics)\n",
        "lr=list(learn_tab.lr_find())[0]\n",
        "learn_tab.fit_flat_cos(100, cbs=[EarlyStoppingCallback()], lr=lr)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>fbeta_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.171351</td>\n",
              "      <td>0.154867</td>\n",
              "      <td>0.936555</td>\n",
              "      <td>0.944082</td>\n",
              "      <td>0.936555</td>\n",
              "      <td>0.938713</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.150348</td>\n",
              "      <td>0.152932</td>\n",
              "      <td>0.936342</td>\n",
              "      <td>0.943704</td>\n",
              "      <td>0.936342</td>\n",
              "      <td>0.938474</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.137638</td>\n",
              "      <td>0.161810</td>\n",
              "      <td>0.932936</td>\n",
              "      <td>0.936492</td>\n",
              "      <td>0.932936</td>\n",
              "      <td>0.934234</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement since epoch 1: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOOBG7qgp6ju"
      },
      "source": [
        "## Build Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs2CPfj97XCS"
      },
      "source": [
        "### Text DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5eznrOofSM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ca7702ee-c850-4180-9fa4-a4603427033e"
      },
      "source": [
        "# language model dataloaders\n",
        "dls_lm = TextDataLoaders.from_df(df,\n",
        "                                 path=path,\n",
        "                                 text_col=text_names, \n",
        "                                 is_lm=True, \n",
        "                                 label_col=y_names,\n",
        "                                 splits=splits, \n",
        "                                 bs=64)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iKEbfD56rd6Q",
        "outputId": "0dc40439-af28-41be-a10f-2d7ab635190b"
      },
      "source": [
        "# text-classification dataloaders\n",
        "dls_txt = TextDataLoaders.from_df(df, \n",
        "                                 path=path, \n",
        "                                 text_col=text_names,\n",
        "                                 label_col=y_names, \n",
        "                                 bs=64, \n",
        "                                 text_vocab = dls_lm.vocab,\n",
        "                                 splits=splits\n",
        "                                 )\n",
        "dls_txt.show_batch()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxfld 1 xxmaj it 's huge . xxfld 2 xxmaj no , but i 'm not a small person . i 'm 5'8 , a size 6 on top , 8 on bottom . i do n't love this on the model online , but i saw this on xxunk 's blog , love xxunk , and thought it looked amazing . i tried it on in my retailer , and while they only had a m / l , since i 'm tall , i figured that 'd be fine . oh . no . not fine . it 's huge . like , it could almost cover a twin bed . it was a couple inches longer on me than on the model , and does n't xxunk down in a drape nearly as well , so just looks , h xxrep 3 u ge . i</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxfld 1 xxmaj great skirt , but size up a lot if you 're curvy xxfld 2 i understand this is a pencil skirt , so it 's gon na be more body hugging . however , this really did seem to run small . i only tried it on because it was on sale and there was a promotion . my thoughts below : \\n▁ xxrep 11 _ \\n pros : \\n - great design that will match with a lot of things . \\n - very soft and comfortable overall due to being part modal . lots of stretch . \\n - no dry cleaning here . hand wash , which is a plus for me . \\n - it 's a thicker knit , but it 's breathable , too . no issues with being see - through . \\n - re</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxfld 1 xxmaj very pretty -- runs very long though ! xxfld 2 xxmaj this is long -- as it is shown in the picture . i am five 8 , and it 's actually too long for me . it looks a bit matronly on as it 's just so long . i loved the fabric -- it 's not heavy and it 's super soft . i think it runs one size big . it 's made very well , and as i stated , it is a nice fabric with a soft hand . it would be nice for a crisp fall day . that being said , the length just is n't right and does nothing for me . i 'm five 8 and slender . i definitely do not think a petite woman would like this or be</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxbos xxfld 1 xxmaj beautiful one - of - a - kind jacket xxfld 2 i love this coat ! i purchased the size 6 . i am a size 6 petite , but they were out . plus i wanted the coat to be a little longer . i was n't a fan of how high it was on the model . it fit as i expected . i will have to take up the arm length , and it hit a little longer than it did on the model . i am 5 ' 120 pounds . 34c \\n\\n the quality is what i expected . it 's excellent with lining . color is as shown . this coat will go with everything ! i plan to dress it up and down . i purchased the \" orange \" pants and the</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxbos xxfld 1 xxmaj small in bust , tts in torso xxfld 2 xxmaj this top is a tough one . i ordered my usual medium . i 'm 5'7 \" , 165 lbs , 34c , and wear a 10 / m pretty much all the time ( tops and bottoms ) . let 's begin : \\n\\n the bad : \\n when i tried it on , i found the bust to be too small , and the darting on the sides puckered in a very non - flattering way . the ruffle at the neck stood up more like a mock turtleneck ( which is not my scene ) . also , the fabric seemed a little thin for chambray . \\n\\n the good : \\n the pattern is adorable . the sleeveless design would be great under xxunk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxbos xxfld 1 xxmaj cute leggings for cooler days , but be aware of fit xxfld 2 xxmaj i 've been wanting to add some cords to my wardrobe and had to give these a try . i ordered the blue color on - line in size 31 . i 'm somewhat in - between size 30 and 31 in jeans right now , so i thought i 'd be on the safe side and go up . i ended up keeping these and i 'm happy with my purchase , although i do feel like the cut of the leggings is a bit off for me . i am a proportional hour - glass shape and i found these leggings to be quite snug in the thigh , while being oversized in the waist . \\n in the end ,</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xxbos xxfld 1 xxmaj not quite an every day staple , but nice top xxfld 2 i wanted a nice , well - fitting top that would work with trousers , jeans , and skirts alike , and be a nice wardrobe staple . i got two of these tops - one size s ( black ) and one m ( turquoise ) . the size m is gigantic and i have to return it . the size s is also a whole xxunk shirt . the top is really long and has a multi - level bottom , as well as the pocket , making it not just a simple top but a rather \" loud \" top . nevertheless , i 'm keeping the size s ( black ) as a versatile shirt that i can hopefully xxunk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxbos xxfld 1 xxmaj beautiful , beautiful , beautiful xxrep 3 ! xxfld 2 xxmaj this sweater is a beautiful , quality , well - made , piece of art ! it looks on , exactly like it looks online . when i ordered it , i was worried that my usual size , xs , might be too tight . however , it is a perfect fit : it is fitted , yet , it still has a comfortable looseness ( with some extra room in the length of the arms ) . for reference , i am 122 lbs , 5'4 \" , 36 - 17 - 36 . the color is a perfect match to the pilcro serif navy / xxunk leggings . of course , i am always apprehensive about stretching and / or shrink</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xxbos xxfld 1 xxmaj the perfect denim midi skirt xxfld 2 i followed everyone 's advice in the reviews and ordered up one size . i have a 32 inch waist , but size 10 's ( and 30 's in pilcro hyphens ) usually fit me . i ordered the 12 in this skirt , and it fits perfect . it 's form fitting at waist and hips and then flares out , but i 'm curvy . if you are straighter , it will be looser around the hips . i love the length . it hits me mid calf , so a bit lower than it does on the model . i 'm 5'5 \" tall . the fabric is soft , but has no stretch . it 's 100 % cotton . there is a</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaelmbwdpXmm",
        "outputId": "44725cb8-972d-49aa-f8e7-c5c218fff688"
      },
      "source": [
        "# to get DataLoader:  use [0] for train, use [1] for test\n",
        "\n",
        "### TBD??? list(txt_dls[1].get_idxs())[:5] is NOT shuffled\n",
        "list(dls_txt[0].get_idxs())[:5], list(dls_txt[1].get_idxs())[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([18436, 1448, 16698, 11543, 14609], [2248, 1046, 631, 3033, 215])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAZgDmNU5sSA"
      },
      "source": [
        "### Text Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-28QMayWueX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "a05fd7ec-5049-49e4-cae6-91c03379cf40"
      },
      "source": [
        "# language model\n",
        "learn_lm = language_model_learner(dls_lm, AWD_LSTM, drop_mult = 0.3).to_fp16()\n",
        "#learn_lm.fit_one_cycle(3, 1e-2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "1L2p7ItbnfgY",
        "outputId": "c0918b95-39b3-471b-f9b5-3c8a61098574"
      },
      "source": [
        "learn_txt = text_classifier_learner(dls_txt, AWD_LSTM, drop_mult=0.5, metrics=metrics).to_fp16()\n",
        "lr=list(learn_txt.lr_find())[0]\n",
        "learn_txt.fit_flat_cos(100, cbs=[EarlyStoppingCallback()], lr=lr)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='23' class='' max='293' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      7.85% [23/293 01:08<13:20 0.7824]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-20:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-213126c86d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_classifier_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_fp16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlearn_txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_flat_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStoppingCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggest_funcs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggest_funcs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/text/models/core.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m#Note: this expects that sequence really begins on a round multiple of bptt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mreal_bs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mreal_bs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/text/models/awdlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, from_embeds)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnew_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mnew_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhid_dp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/text/models/awdlstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# To avoid the warning that comes because the weights aren't flattened.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 680\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 302) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnBC96KOFgpO"
      },
      "source": [
        "## Combine DataLoaders\n",
        "\n",
        "> 'What we want to do is override both DataLoader's shuffle_fn, as what this function does is return a list of index's to grab. If the index's are the same, the data is the same, and that's all there is to it. In this particular case, we're going to be calling their shuffle_fn, etc multiple times, so we need to keep track of who actually is being called. We'll store this in a value called count. When it's 0, we'll grab some index's. When it's 1, we will return those index's (this is done at the beginning of each epoch to shuffle the DataLoader'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9yjx0FkNIBw"
      },
      "source": [
        "### MixedDLS\n",
        "\n",
        "ATTN: DataLoaders vs DataLoader ###TBD???\n",
        "\n",
        "- DataLoaders loads df and then splits df into train data & valid data\n",
        "\n",
        "- DataLoader loads train_df and valid_df separately and results in \n",
        "\n",
        "  - `dl_tab_train`, `dl_tab_test` for tabular\n",
        "\n",
        "  - `dl_txt_train`, `dl_txt_test` for text\n",
        "\n",
        "Example: https://github.com/MaramMonshi/CovidXrayNet/blob/main/Dataset/COVIDcxr-mixed.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDYrrr3xDDWU"
      },
      "source": [
        "from fastai.data.load import _loaders, _FakeLoader\n",
        "\n",
        "class MixedDLS():\n",
        "    def __init__(self, tab_dls:TabularDataLoaders, txt_dls:TextDataLoaders, device = device):\n",
        "        \"Stores away `tab_dl` and `txt_dl`, and overrides `shuffle_fn`\"\n",
        "        self.device = device\n",
        "        tab_dls.shuffle_fn = self.shuffle_fn\n",
        "        txt_dls.shuffle_fn = self.shuffle_fn\n",
        "        self.dls = [tab_dls, txt_dls]\n",
        "        self.count = 0\n",
        "        self.fake_l = _FakeLoader(self, False, 0, 0, persistent_workers=False) # persistent_workers: https://bowenroom.github.io/myBlog/pytorch/fastai/2021/01/27/fastai-dataloader.html\n",
        "    \n",
        "    def __len__(self): \n",
        "        \"\"\"to return the length of one of our DataLoaders\"\"\"\n",
        "        return len(self.dls[0])\n",
        "        \n",
        "    def shuffle_fn(self, idxs):\n",
        "        \"Generates a new list of index that will be stored inside `self.rng`; those indexs will be changed every 2 times shuffle_fn is called to ensure both tab_dls and txt_dls get the same set of indexs for batch.\"\n",
        "        if self.count == 0: # if we haven't generated an rng yet\n",
        "            self.rng = self.dls[0].rng.sample(idxs, len(idxs))\n",
        "            self.count += 1\n",
        "            return self.rng\n",
        "        else:\n",
        "            self.count = 0\n",
        "            return self.rng\n",
        "        \n",
        "    def to(self, device): \n",
        "        \"\"\"to set the name of device\"\"\"\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Iterate over your `DataLoader`\n",
        "        iterator needs to \n",
        "        - take all of our batches from our loaders and \n",
        "        - perform the `after_batch` transform for those outputs from their respective `DataLoader` before finally being put into a batch, also \n",
        "        - moving each to the `device`.\n",
        "        \"\"\"\n",
        "        z = zip(*[_loaders[i.fake_l.num_workers==0](i.fake_l) for i in self.dls])\n",
        "        for b in z:\n",
        "            if self.device is not None: \n",
        "                b = to_device(b, self.device)\n",
        "            batch = []\n",
        "            batch.extend(self.dls[0].after_batch(b[0])[:2]) # tabular cat and cont\n",
        "            batch.append(self.dls[1].after_batch(b[1][0])) # text ???TBD\n",
        "            try: # In case the data is unlabelled\n",
        "                batch.append(b[1][1]) # y\n",
        "                yield tuple(batch)\n",
        "            except:\n",
        "                yield tuple(batch)\n",
        "\n",
        "    def one_batch(self):\n",
        "        \"\"\"Grab a batch from the `DataLoader`\"\"\"\n",
        "        with self.fake_l.no_multiproc(): res = first(self)\n",
        "        if hasattr(self, 'it'): delattr(self, 'it')\n",
        "        return res\n",
        "\n",
        "    def show_batch(self):\n",
        "        \"Show a batch from multiple `DataLoaders`\"\n",
        "        for dl in self.dls:\n",
        "            dl.show_batch()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyte5JVAnfWY"
      },
      "source": [
        "mixed_dls = MixedDLS(dls_tab, dls_txt)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lmYxs3Z-wsCe",
        "outputId": "90862a90-a87f-4186-f803-944d1e3470c4"
      },
      "source": [
        "mixed_dls.show_batch()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Age</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Recommended IND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1053</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "      <td>3.0</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>927</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Sweaters</td>\n",
              "      <td>5.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>571</td>\n",
              "      <td>General</td>\n",
              "      <td>Trend</td>\n",
              "      <td>Trend</td>\n",
              "      <td>5.0</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>387</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "      <td>5.0</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1078</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>5.0</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>826</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>5.0</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>829</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>4.0</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>2.800000e+01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>931</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Sweaters</td>\n",
              "      <td>4.0</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>964</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Jackets</td>\n",
              "      <td>Jackets</td>\n",
              "      <td>5.0</td>\n",
              "      <td>24.999999</td>\n",
              "      <td>-1.312539e-08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>988</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Skirts</td>\n",
              "      <td>3.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.500000e+01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxfld 1 xxmaj it 's huge . xxfld 2 xxmaj no , but i 'm not a small person . i 'm 5'8 , a size 6 on top , 8 on bottom . i do n't love this on the model online , but i saw this on xxunk 's blog , love xxunk , and thought it looked amazing . i tried it on in my retailer , and while they only had a m / l , since i 'm tall , i figured that 'd be fine . oh . no . not fine . it 's huge . like , it could almost cover a twin bed . it was a couple inches longer on me than on the model , and does n't xxunk down in a drape nearly as well , so just looks , h xxrep 3 u ge . i</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxfld 1 xxmaj works if you 're broad shouldered xxfld 2 xxmaj if you are like me and your shoulders are broader than your hips , the boat - neck on this wo n't be too wide on you . \\n▁ xxrep 10 - \\n i am normally a m or l in retailer tops , and went with the m , and i have very large biceps . if you 're broad - shouldered but have smaller arms , i would recommended sizing down a size . \\n▁ xxrep 10 - \\n i have a very long torso and did n't find this to be too short … but i love jeans with a 10 \" rise . if you are going to pair this with low or medium ( 8.5 \" ) rise jeans , then yes , you will</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxfld 1 xxmaj so comfy , great cut , pockets , win for petites xxfld 2 xxmaj my new favorite ! i would n't have thought twice about this dress xxunk on a rack in store , but after seeing so many cute pics of ladies in this dress , i caved . i needed a petite , so ordered a sp and xsp . the length on both is perfect . i 'm 5'0 \" and both hit above my knee in front and hit at in back and on sides . i did n't try on a regular in store , but based on the sp / xsp , i 'm pretty sure there 'd be too much material for a petite frame . the xsp is cut slimmer and if i had a tiny waist , i 'd xxunk</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxbos xxfld 1 xxmaj not flattering . xxfld 2 1 . i 've been waiting forever for these to finally arrive . i was a bit disappointed . \\r\\n\\r\\n 2 . i 'm 5'5 \" tall , 145 lbs , and 38 - 32 - 40 . my normal size 30 's fit me perfectly , if a bit loose . they fit a lot like the hyphens . \\r\\n\\r\\n 3 . the legs are short and wide . they hit me at the ankle , which made them look like high waters on me . \\r\\n\\r\\n 4 . the legs are very , very wide , and i did n't think that was flattering on me . \\r\\n\\r\\n 5 . same comfy fabric and fit as the hyphens , except the front seemed to dip low at the waist i</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxbos xxfld 1 xxmaj could n't wait to see this in person ! xxfld 2 i had my eye on this dress since it fist came out , but hesitated to order due to some of the lower reviews . when i got a chance to try it on - i loved it ! i did go up a size . i am 5'5 \" so i had it shortened to above the knee , i did n't mind losing the unfinished hem - had the hem match that of the pockets . i am a 34c but the bodice is stable and even if i pull at it , it stays put ! so happy to find this , especially on sale ! i plan to wear it at our company party which is help on a large xxunk bo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxbos xxfld 1 xxmaj fades ! falling apart . xxfld 2 xxmaj within 2 washings the color faded to a not so black black , like a pair of pants that has been washed over a year 's use . after 5 or so washes the hook and eye closure began to fall off . the pants fit well , albeit a bit short ( i 'm 5'9 \" ) and they run small . i sized up to a 6 , when i usually am between a 2 or 4 . i let the hem out , sewed the hook and eye closure back on and xxunk them , and now they are good to go , but for nearly $ 90 i do n't expect to have to do this much work . these are not my first</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xxbos xxfld 1 xxmaj great transitional dress ! xxfld 2 xxmaj after reading the reviews , stating that this dress was a tent and only fit for the tall and small chested , i kind of had a battle of xxunk in my head over ordering it . it is very \" me , \" but me is also 5'5 , curvy , and xxunk a 36 g bust . i had to post a review , because i received the dress today , and i actually love it . i ordered a 16 and i love the fit . i know it 's flowy , but on me , it 's far from tent - like . i think it 's great now as a pre - fall piece with some sandals and a jean jacket , and as</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxbos xxfld 1 xxmaj quite soft but prone to pilling xxfld 2 xxmaj this ' poor boy ' mock t - neck / high crew neck top looks a tiny bit more olive to me than the online photos . the fit runs on the smaller size , and the sleeves will be bracelet length or 3 / 4 length for taller women . \\n . \\n i tried a size xs that was in the store and it fit with the sleeves just above my wrists , but a size s would have been fine too ( i 'm 5'2 \" , currently 33 - 25 - 37 , narrow shoulders and xxunk reference , even the size m of the short sleeve version fit fine , so there is a lot of give . \\n . \\n no</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xxbos xxfld 1 xxmaj cute cover - up or summer top &amp; shorts ! xxfld 2 xxmaj lightweight , soft cotton top and shorts . i think it 's meant to be a beach cover - up but i 'm wearing it as a thin , light - weight summer outfit on these hot hot days . the top has a loose elastic around the bottom which i did n't realize when i ordered it , but i like it and it matches the look in the photos . and the shorts are very low - cut - do n't expect them up around your waist . again , i like that . some might want to wear a cami underneath because it 's a thin cotton but i 'm fine as - is . i bought it i</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JjmAkv_ge1J",
        "outputId": "8b31e5db-92fb-4959-abd4-ea9965fbfd77"
      },
      "source": [
        "dls_tab[0].get_idxs()[:7], dls_tab[1].get_idxs()[:7]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([7492, 8306, 10954, 9004, 9175, 11336, 13762], [0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC0cqSrwkr3y",
        "outputId": "e17af320-f867-4762-9a54-16e15b05db8a"
      },
      "source": [
        "list(dls_txt[0].get_idxs())[:7], list(dls_txt[1].get_idxs())[:7]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([18436, 6118, 16780, 18686, 16978, 3167, 13587],\n",
              " [2248, 1046, 631, 3033, 215, 1465, 1658])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPE7xc9Og_6o"
      },
      "source": [
        "### Testing: for train data, dbck mixed_dls line up tabular & text correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plNMyNYswzcJ"
      },
      "source": [
        "\n",
        "mixed_dls_train = MixedDLS(dls_tab[0], dls_txt[0]) # 0 for train"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKNkRqxzxXRY",
        "outputId": "249e2bb8-6783-4c19-f923-ef939a42def8"
      },
      "source": [
        "mixed_dls_train.dls[0].get_idxs()[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10082, 7837, 5429, 14521, 2930, 4039, 9681, 11515, 5976, 10934]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXBGKogjypId",
        "outputId": "10e53db5-463c-4662-fd4a-c35ef97aa1b0"
      },
      "source": [
        "mixed_dls_train.dls[1].get_idxs()[:10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10082, 7837, 5429, 14521, 2930, 4039, 9681, 11515, 5976, 10934]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeTeGLCfhbG5"
      },
      "source": [
        "### Testing: for test data, dbck mixed_dls line up tabular & text correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdRMC2g5hfxs"
      },
      "source": [
        "\n",
        "mixed_dls_test = MixedDLS(dls_tab[1], dls_tab[1]) # 1 for test"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBlKaCRih24P",
        "outputId": "cd54fa5f-1797-4239-a75f-cd66f788c0bf"
      },
      "source": [
        "mixed_dls_test.dls[0].get_idxs()[:10] ### TBD?? it never changes <= not shuffled properly"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbcpPIm2h28O",
        "outputId": "a0134a7a-3366-432a-c075-634e4ace91dc"
      },
      "source": [
        "mixed_dls_test.dls[1].get_idxs()[:10] ### TBD?? it never changes <= not shuffled properly"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1OlhAUZyyNl"
      },
      "source": [
        "The above shows that the data is being shuffled the exact same way for `tab_dls` and `txt_dls`.\n",
        "\n",
        "\n",
        "Now let's exam `.one_batch()`: one_batch will need to call the first from the DataLoader (which is just next(iter(dl))), and if we are keeping track of an iterator, delete it. Finally returning our batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfnWRW_zyqwX",
        "outputId": "69ae5f8d-dbe9-43bf-a937-6a313548c57d"
      },
      "source": [
        "batch = mixed_dls.one_batch()\n",
        "\n",
        "batch[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <generator object MixedDLS.__iter__ at 0x7fd8b9487550>\n",
            "RuntimeError: generator ignored GeneratorExit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 959,    2,    1,   14],\n",
              "        [ 834,    2,    5,   18],\n",
              "        [ 505,    1,    6,   20],\n",
              "        [ 346,    3,    3,    6],\n",
              "        [ 984,    1,    2,    4],\n",
              "        [ 736,    1,    5,    1],\n",
              "        [ 739,    1,    5,    1],\n",
              "        [ 838,    1,    5,   18],\n",
              "        [ 871,    2,    4,    7],\n",
              "        [ 894,    2,    1,   16],\n",
              "        [ 780,    1,    5,    9],\n",
              "        [ 745,    1,    5,    1],\n",
              "        [ 988,    1,    2,    4],\n",
              "        [ 730,    1,    5,    1],\n",
              "        [ 958,    2,    1,   14],\n",
              "        [ 852,    1,    5,   18],\n",
              "        [ 775,    2,    5,    9],\n",
              "        [ 785,    2,    5,    9],\n",
              "        [ 562,    2,    3,   12],\n",
              "        [1000,    2,    2,    4],\n",
              "        [ 739,    2,    5,    1],\n",
              "        [ 739,    1,    5,    1],\n",
              "        [1056,    1,    2,    4],\n",
              "        [ 987,    1,    2,    4],\n",
              "        [ 984,    1,    2,    4],\n",
              "        [ 754,    1,    5,    1],\n",
              "        [ 942,    1,    1,    8],\n",
              "        [ 890,    2,    4,    7],\n",
              "        [1000,    1,    2,    4],\n",
              "        [ 902,    2,    1,   16],\n",
              "        [ 984,    2,    2,    4],\n",
              "        [ 880,    1,    4,    7],\n",
              "        [ 741,    1,    5,    1],\n",
              "        [ 482,    1,    1,   15],\n",
              "        [ 984,    1,    2,    4],\n",
              "        [ 823,    2,    5,    5],\n",
              "        [ 936,    1,    1,    8],\n",
              "        [ 813,    2,    5,    5],\n",
              "        [ 995,    1,    2,    4],\n",
              "        [ 934,    1,    1,    8],\n",
              "        [ 784,    1,    5,    9],\n",
              "        [1003,    2,    2,    4],\n",
              "        [ 974,    2,    1,   14],\n",
              "        [ 785,    1,    5,    9],\n",
              "        [ 728,    1,    5,    1],\n",
              "        [ 776,    2,    5,    9],\n",
              "        [ 941,    2,    1,    8],\n",
              "        [ 771,    2,    5,    9],\n",
              "        [ 978,    2,    2,    4],\n",
              "        [ 777,    1,    5,    9],\n",
              "        [ 739,    2,    5,    1],\n",
              "        [ 728,    2,    5,    1],\n",
              "        [ 770,    2,    5,    9],\n",
              "        [1016,    1,    2,    4],\n",
              "        [ 243,    3,    3,   19],\n",
              "        [ 780,    1,    5,    9],\n",
              "        [ 984,    1,    2,    4],\n",
              "        [ 324,    2,    3,   12],\n",
              "        [ 794,    2,    5,    9],\n",
              "        [ 934,    2,    1,    8],\n",
              "        [ 485,    3,    3,   10],\n",
              "        [ 769,    1,    5,    9],\n",
              "        [ 780,    1,    5,    9],\n",
              "        [ 984,    1,    2,    4]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5OViY1yzxps",
        "outputId": "4e36b9fe-4cc6-4ec5-af1f-4e6e59702cd0"
      },
      "source": [
        "batch[1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0703, -0.1012, -0.4515],\n",
              "        [ 0.7243, -1.6479, -0.4515],\n",
              "        [ 0.7243, -0.1012, -0.0900],\n",
              "        [ 0.7243, -0.7524, -0.4515],\n",
              "        [ 0.7243,  0.5501, -0.4515],\n",
              "        [ 0.7243,  1.8527, -0.2708],\n",
              "        [-0.1730,  1.5270,  4.6093],\n",
              "        [-0.1730, -0.3454, -0.2708],\n",
              "        [ 0.7243, -1.4851, -0.4515],\n",
              "        [-1.0703, -1.6479,  2.2596],\n",
              "        [-0.1730,  0.3873, -0.4515],\n",
              "        [ 0.7243,  0.1431,  0.0907],\n",
              "        [-0.1730, -0.5896,  0.6329],\n",
              "        [ 0.7243, -0.0197, -0.4515],\n",
              "        [ 0.7243,  0.0617, -0.4515],\n",
              "        [-1.0703,  0.0617, -0.4515],\n",
              "        [-0.1730,  0.2245, -0.4515],\n",
              "        [-0.1730, -0.5896, -0.4515],\n",
              "        [-0.1730, -0.3454, -0.2708],\n",
              "        [-2.8649,  1.5270, -0.4515],\n",
              "        [-0.1730,  0.7129, -0.4515],\n",
              "        [-1.0703, -1.3223, -0.4515],\n",
              "        [ 0.7243, -0.6710, -0.2708],\n",
              "        [ 0.7243,  2.0969, -0.2708],\n",
              "        [-1.0703,  0.9572, -0.4515],\n",
              "        [-1.0703,  0.4687, -0.4515],\n",
              "        [-1.0703,  1.8527, -0.2708],\n",
              "        [ 0.7243,  2.2597, -0.4515],\n",
              "        [ 0.7243,  1.2014, -0.4515],\n",
              "        [-0.1730,  0.3873, -0.4515],\n",
              "        [-0.1730, -1.1595, -0.4515],\n",
              "        [ 0.7243,  0.5501,  1.7174],\n",
              "        [ 0.7243, -0.8338, -0.4515],\n",
              "        [ 0.7243,  2.0155, -0.2708],\n",
              "        [ 0.7243,  1.6084,  3.5248],\n",
              "        [ 0.7243, -0.3454,  1.8981],\n",
              "        [ 0.7243,  0.7129, -0.4515],\n",
              "        [ 0.7243,  2.4225,  0.6329],\n",
              "        [ 0.7243, -0.8338, -0.4515],\n",
              "        [-0.1730,  0.0617,  0.0907],\n",
              "        [-0.1730,  1.7713, -0.4515],\n",
              "        [ 0.7243, -0.2640,  0.4522],\n",
              "        [ 0.7243, -0.6710, -0.4515],\n",
              "        [ 0.7243, -1.4037,  0.0907],\n",
              "        [ 0.7243,  0.5501, -0.4515],\n",
              "        [ 0.7243,  1.6084, -0.4515],\n",
              "        [-0.1730, -0.4268,  0.0907],\n",
              "        [ 0.7243,  1.2014,  1.1752],\n",
              "        [-0.1730, -1.4037, -0.4515],\n",
              "        [ 0.7243, -0.5896,  0.4522],\n",
              "        [ 0.7243,  2.0969, -0.2708],\n",
              "        [-1.9676,  1.3642, -0.4515],\n",
              "        [ 0.7243, -0.8338,  0.2715],\n",
              "        [ 0.7243,  1.7713,  2.6211],\n",
              "        [ 0.7243, -0.1826, -0.0900],\n",
              "        [ 0.7243, -0.5896, -0.0900],\n",
              "        [-0.1730,  0.1431, -0.4515],\n",
              "        [-0.1730, -0.2640, -0.2708],\n",
              "        [ 0.7243,  0.5501, -0.4515],\n",
              "        [ 0.7243,  1.9341, -0.4515],\n",
              "        [ 0.7243, -0.1826, -0.4515],\n",
              "        [ 0.7243, -0.5082, -0.4515],\n",
              "        [ 0.7243, -0.3454, -0.0900],\n",
              "        [ 0.7243, -0.5082, -0.4515]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUjAO2rTz0sW",
        "outputId": "7b6f27b2-22b1-45fd-9f71-675df55a747e"
      },
      "source": [
        "batch[2]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([[   2,    4,   20,  ...,   80,  149,    9],\n",
              "        [   2,    4,   20,  ...,   17,   79,    9],\n",
              "        [   2,    4,   20,  ...,   15, 1074,   23],\n",
              "        ...,\n",
              "        [   2,    4,   20,  ...,   95,    1,    1],\n",
              "        [   2,    4,   20,  ...,    9,    1,    1],\n",
              "        [   2,    4,   20,  ...,    9,    1,    1]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL5jgYjQz3ML",
        "outputId": "2a40036a-c0c1-4783-dc5b-0c181bcfa9ae"
      },
      "source": [
        "batch[3]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorCategory([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr8bUOlG5pO_"
      },
      "source": [
        "### Train+Valid MixedDL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbw5rbae0f1m"
      },
      "source": [
        "train_mixed_dl = MixedDLS(dls_tab[0], dls_txt[0])\n",
        "valid_mixed_dl = MixedDLS(dls_tab[1], dls_txt[1])\n",
        "mixed_dls = DataLoaders(train_mixed_dl, valid_mixed_dl).cuda()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjsgxM2K6S5x"
      },
      "source": [
        "### Joint Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiTOEob357rh",
        "outputId": "6f849ddc-5580-4d5e-d992-878b0d87ede7"
      },
      "source": [
        "o=mixed_dls.one_batch() \n",
        "len(o)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <generator object MixedDLS.__iter__ at 0x7fd8b9487450>\n",
            "RuntimeError: generator ignored GeneratorExit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOOyJs0Z2dSs"
      },
      "source": [
        "\"\"\"def printnorm(self, input, output):\n",
        "     # input is a tuple of packed inputs\n",
        "     # output is a Tensor. output.data is the Tensor we are interested\n",
        "     print('Inside ' + self.__class__.__name__ + ' forward')\n",
        "     print('')\n",
        "     print('input: ', type(input))\n",
        "     print('input[0]: ', type(input[0]))\n",
        "     print('output: ', type(output))\n",
        "     print('')\n",
        "     print('input size:', input[0].size())\n",
        "     print('output size:', output.data.size())\n",
        "     print('output norm:', output.data.norm())\n",
        "\n",
        "\n",
        "learn_tab.model.layers[2][0].register_forward_hook(printnorm)\n",
        "\n",
        "#out = learn_tab.model(o[0], o[1])\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCUZAziQ6gHA"
      },
      "source": [
        "### Pytorch Hooks\n",
        "\n",
        "To extract the input to the layer just before the classifier layer, creat 2 hooks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbYOkCKd57uS"
      },
      "source": [
        "global glb_tab_logits\n",
        "def get_tab_logits(self, inp, out):\n",
        "    global glb_tab_logits\n",
        "    glb_tab_logits = inp\n",
        "    #return None\n",
        "\n",
        "global glb_txt_logits\n",
        "def get_txt_logits(self, inp, out):\n",
        "    global glb_txt_logits\n",
        "    glb_txt_logits = inp"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3D22LDv7Cmr"
      },
      "source": [
        "### Define Multi-Modal Model\n",
        "**Classifiers**\n",
        "Used the default tabular and text classifiers from fastai and just grabbed the logits from each (via pytorch hooks) which are then concated and fed into a linear layer (which is our mixed classifier)\n",
        "\n",
        "**PyTorch Hooks**\n",
        "Note, I'm not sure if I'm grabbing the right thing with the get_tab_logits and get_txt_logits hooks, only grabbing the weight. Its trains ok tho, so maybe its fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flc2gNQP6nKq"
      },
      "source": [
        "tab_model, txt_model=learn_tab.model, learn_txt.model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXJJawCP6wgl",
        "outputId": "bcb62005-fb27-4c4d-effc-d28252b101c0"
      },
      "source": [
        "tab_model.layers[2][0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=100, out_features=2, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZXMSwD07L5q",
        "outputId": "813fdb3b-121e-49f1-ac13-75cbbb65c717"
      },
      "source": [
        "txt_model[1].layers[1][2]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=50, out_features=2, bias=False)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A28Ncgl57xF"
      },
      "source": [
        "num_classes=len(set(df[y_names]))\n",
        "\n",
        "class TabTxt(nn.Module):\n",
        "    def __init__(self, tab_model, txt_model, num_classes=num_classes, device = device): \n",
        "        super(TabTxt, self).__init__()\n",
        "        self.tab_model = tab_model\n",
        "        self.txt_model = txt_model\n",
        "        \n",
        "        self.mixed_cls = nn.Linear(100+50, num_classes)\n",
        "        self.tab_cls = nn.Linear(100, num_classes)\n",
        "        self.txt_cls = nn.Linear(50, num_classes)\n",
        "        \n",
        "        #self.print_handle = self.tab_model.layers[2][0].register_forward_hook(printnorm)\n",
        "        #tab_model.layers[2]\n",
        "        #txt_model[1].layers[1][2]\n",
        "        \n",
        "        self.tab_handle = self.tab_model.layers[2][0].register_forward_hook(get_tab_logits) ### TBD???\n",
        "        self.txt_handle = self.txt_model[1].layers[1][2].register_forward_hook(get_txt_logits) ### TBD???\n",
        "        self.device=device\n",
        "\n",
        "    def remove_my_hooks(self):\n",
        "        self.tab_handle.remove()\n",
        "        self.txt_handle.remove()\n",
        "        #self.print_handle.remove()\n",
        "        return None\n",
        "        \n",
        "    def forward(self, x_cat, x_cont, x_txt):\n",
        "        # Tabular Classifier\n",
        "        #tab_pred = self.tab_model(x_cat.to(self.device), x_cont.to(self.device))        \n",
        "        tab_pred = self.tab_model(x_cat, x_cont)        \n",
        "        \n",
        "        # Text Classifier\n",
        "        #txt_pred = self.txt_model(x_txt.to(self.device))\n",
        "        txt_pred = self.txt_model(x_txt)\n",
        "        \n",
        "        # Logits\n",
        "        tab_logits = glb_tab_logits[0]   # Only grabbling weights, not bias'\n",
        "        txt_logits = glb_txt_logits[0]   # Only grabbling weights, not bias'\n",
        "        mixed = torch.cat((tab_logits, txt_logits), dim=1)\n",
        "        \n",
        "        # Mixed Classifier\n",
        "        mixed_pred = self.mixed_cls(mixed)\n",
        "        return (tab_pred, txt_pred, mixed_pred)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-yFutfj8RR9"
      },
      "source": [
        "### Gradient Blending, loss function\n",
        "\n",
        "Same as : https://forums.fast.ai/t/gradient-blending-for-multi-modal-models-in-progress/75645/3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKS1nBIm57z-"
      },
      "source": [
        "def ModCELoss(pred, targ, ce=True):\n",
        "    pred = pred.softmax(dim=-1)\n",
        "    targ = targ.flatten().long()\n",
        "    if ce:\n",
        "        loss = F.cross_entropy(pred, targ)\n",
        "    else:\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, targ)\n",
        "    #loss = torch.mean(ce)\n",
        "    return loss\n",
        "\n",
        "class myGradientBlending(nn.Module):\n",
        "    def __init__(self, tab_weight=0.0, txt_weight=0.0, tab_txt_weight=1.0, loss_scale=1.0, use_cel=True):\n",
        "        \"Expects weights for each model, the combined model, and an overall scale\"\n",
        "        super(myGradientBlending, self).__init__()\n",
        "        self.tab_weight = tab_weight\n",
        "        self.txt_weight = txt_weight\n",
        "        self.tab_txt_weight = tab_txt_weight\n",
        "        self.ce =  use_cel\n",
        "        self.scale = loss_scale\n",
        "        \n",
        "    def forward(self, xb, yb):\n",
        "        tab_out, txt_out, tv_out = xb\n",
        "        targ = yb\n",
        "        \"Gathers `self.loss` for each model, weighs, then sums\"\n",
        "        tv_loss = ModCELoss(tv_out, targ, self.ce) * self.scale\n",
        "        t_loss = ModCELoss(tab_out, targ, self.ce) * self.scale\n",
        "        v_loss = ModCELoss(txt_out[0], targ, self.ce) * self.scale ### TBD???\n",
        "        \n",
        "        weighted_t_loss = t_loss * self.tab_weight\n",
        "        weighted_v_loss = v_loss * self.txt_weight\n",
        "        weighted_tv_loss = tv_loss * self.tab_txt_weight\n",
        "        \n",
        "        loss = weighted_t_loss + weighted_v_loss + weighted_tv_loss\n",
        "        return loss"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSZSKavytiS-"
      },
      "source": [
        "### testing individual steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icabIM5etmlj"
      },
      "source": [
        "multi_model = TabTxt(learn_tab.model, learn_txt.model)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yahEkxEg4_w0",
        "outputId": "5e27c0a8-f003-4cb7-ffb6-4be97d439669"
      },
      "source": [
        "o[0].shape, o[1].shape , o[2].shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 4]), torch.Size([64, 3]), torch.Size([64, 69]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F43QfqRItmt_"
      },
      "source": [
        "#tab_pred, txt_pred, mixed_pred = multi_model(o[0], o[1] , o[2])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rWmEdhStmxb"
      },
      "source": [
        "#%debug"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IETgo9h9LIZ"
      },
      "source": [
        "###  testing learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYa4K37a572f"
      },
      "source": [
        "\n",
        "def t_accuracy(inp, targ, axis=-1):\n",
        "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
        "#     print(inp[0])\n",
        "#     print(inp[0].argmax(dim=axis))\n",
        "#     print(targ)\n",
        "    pred,targ = flatten_check(inp[0].argmax(dim=axis), targ)\n",
        "    return (pred == targ).float().mean()\n",
        "\n",
        "def v_accuracy(inp, targ, axis=-1):\n",
        "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
        "    pred,targ = flatten_check(inp[1].argmax(dim=axis), targ)\n",
        "    return (pred == targ).float().mean()\n",
        "\n",
        "def tv_accuracy(inp, targ, axis=-1):\n",
        "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
        "    pred,targ = flatten_check(inp[2].argmax(dim=axis), targ)\n",
        "    return (pred == targ).float().mean()\n",
        "\n",
        "def weighted_accuracy(inp, targ, axis=-1, w_t=0.333, w_v=0.333, w_tv=0.333):\n",
        "    t_inp = inp[0] * w_t\n",
        "    v_inp = inp[1] * w_v\n",
        "    tv_inp = inp[2] * w_tv\n",
        "    inp_fin = (t_inp + v_inp + tv_inp)/3\n",
        "    pred,targ = flatten_check(inp_fin.argmax(dim=axis), targ)\n",
        "    return (pred == targ).float().mean()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWKnWwVz9yHe"
      },
      "source": [
        "### Testing: train Tabular learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "SNZveS1S9qsG",
        "outputId": "3052ae16-8f54-4caf-ae0d-06476a8910c8"
      },
      "source": [
        "learn_tab = tabular_learner(dls_tab, metrics=metrics)\n",
        "learn_tab.fit_one_cycle(3)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_score</th>\n",
              "      <th>recall_score</th>\n",
              "      <th>fbeta_score</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.215196</td>\n",
              "      <td>0.186975</td>\n",
              "      <td>0.931871</td>\n",
              "      <td>0.936314</td>\n",
              "      <td>0.931871</td>\n",
              "      <td>0.933421</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.153555</td>\n",
              "      <td>0.155288</td>\n",
              "      <td>0.930381</td>\n",
              "      <td>0.933268</td>\n",
              "      <td>0.930381</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.135080</td>\n",
              "      <td>0.160218</td>\n",
              "      <td>0.925484</td>\n",
              "      <td>0.923607</td>\n",
              "      <td>0.925484</td>\n",
              "      <td>0.924236</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iVXSjm598LB"
      },
      "source": [
        "### Testing: train Text learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKAp5vzh-H34",
        "outputId": "94df9821-52a7-4053-d4a8-6fd48c2c6711"
      },
      "source": [
        "learn_txt = text_classifier_learner(dls_txt, AWD_LSTM, drop_mult=0.5, metrics=metrics).to_fp16()\n",
        "#learn_txt.fit_one_cycle(1, 0.02)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6BOOybxVLW1"
      },
      "source": [
        "### Testing: train mixed learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVPaL60Q575Q"
      },
      "source": [
        "# Get uni-modal models, ugly but quick way to grab a tabular and vision model\n",
        "txt_model = text_classifier_learner(dls_txt, AWD_LSTM, drop_mult=0.5, metrics=metrics).model\n",
        "tab_model = tabular_learner(dls_tab, metrics=accuracy).model\n",
        "\n",
        "# Create our Multi-Modal model\n",
        "multi_model = TabTxt(tab_model, txt_model)\n",
        "\n",
        "# Set weights for each loss\n",
        "tab_w = 0.15\n",
        "txt_w = 0.6\n",
        "tt_w = 0.25\n",
        "\n",
        "# Initialise Loss\n",
        "gb_loss = myGradientBlending(tab_weight=tab_w, txt_weight=txt_w, tab_txt_weight=tt_w, \n",
        "                             loss_scale=1.0, use_cel=True)\n",
        "\n",
        "# Define accuracy weights\n",
        "w_accuracy = partial(weighted_accuracy, w_t=tab_w, w_v=txt_w, w_tt=tt_w)\n",
        "\n",
        "metrics = [t_accuracy,v_accuracy,tv_accuracy, w_accuracy]\n",
        "cbs=[]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGdSUE3KBeOE"
      },
      "source": [
        "multi_learn = Learner(mixed_dls, multi_model, gb_loss, cbs=cbs, metrics=metrics)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "KL_eEoQC24zF",
        "outputId": "51b69a69-371c-4e2b-fdfa-79d28b869f54"
      },
      "source": [
        "multi_learn.lr_find()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <generator object MixedDLS.__iter__ at 0x7fd8b13a39d0>\n",
            "RuntimeError: generator ignored GeneratorExit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(valley=0.0005754399462603033)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXzU9Z348dd7JnfIASThSALhPuQ2ooIo3kct2lpP1qu2ttvaY9dta/vb2q523e32WNfW2nqhbrXq2laxoKhVFEGRiNxnCIGEMwkkkDuTef/+mO8Mk2SSTEiGJMz7+Xjkkczne+QzEb/v+Xzen0NUFWOMMSZcrt6ugDHGmP7FAocxxpguscBhjDGmSyxwGGOM6RILHMYYY7rEAocxxpguiWjgEJErRGS7iBSKyH0hjt8hImUiss75+krQsdtFZKfzdXtQ+XLnnv5rsiL5HowxxrQkkZrHISJuYAdwKVAKrAFuVtUtQefcAeSr6j2trh0EFAD5gAKfAmeq6lERWQ78i6oWhFuXjIwMzcvL69b7McaYaPPpp5+Wq2pm6/KYCP7O2UChqhYBiMiLwDXAlg6v8rkceFtVjzjXvg1cAfzpZCqSl5dHQUHYccYYYwwgIntClUeyqyobKAl6XeqUtXadiGwQkVdEJDfMaxc53VQ/FhHp0VobY4zpUG8nx18H8lR1GvA28GwY1yxU1anAPOfr1lAnicjdIlIgIgVlZWU9VmFjjIl2kQwc+4DcoNc5TlmAqlaoaoPz8kngzM6uVVX/9+PAC/i6xNpQ1cdVNV9V8zMz23TRGWOMOUmRzHGsAcaJyCh8D/2bgFuCTxCRYap6wHm5ANjq/LwMeEhEBjqvLwN+KCIxQLqqlotILHA18E4E34Mx5jTX1NREaWkp9fX1vV2VXpOQkEBOTg6xsbFhnR+xwKGqHhG5B18QcANPq+pmEXkAKFDVxcC3RWQB4AGOAHc41x4RkQfxBR+AB5yyZGCZEzTc+ILGE5F6D8aY019paSkpKSnk5eURjSlTVaWiooLS0lJGjRoV1jURG47bl+Tn56uNqjLGhLJ161YmTpwYlUHDT1XZtm0bkyZNalEuIp+qan7r8yPZVWVOkYNV9Ww/dJzUhBhSE2MZlpZAUpz9pzUmXNEcNKDr79+eLqeBe/9vHSsLKwKvMwbE8bdvzWNoWkIv1soYEwkDBgygurqa4uJirr76ajZt2nTK69Dbw3FND9hxqJqLJ2ax6M6z+MWXpnG83sNPFp/6f0zGRIUNL8N/T4Gfpvu+b3i5t2t0ylng6OdqGjyUHW9g1siBXDghi+vzc/nuJeNZtvkQb2462K17qyovrN7Lb9/dyZMrivjjx3vYW1HbQzU3ph/a8DK8/m2oKgHU9/31b3creNx33308+uijgdc//elP+dnPfsbFF1/MrFmzmDp1Kq+99lqH92hubuZ73/seZ511FtOmTeMPf/gDALfddhuvvvpq4LyFCxd2eq9wWODo54oragDIG5wcKPvKvFFMGpbKTxZv4lh900nfe3d5DT/660Z++dYOfrZkK//66iZ+8OcN3a6zMf3W3x+AprqWZU11vvKTdOONN/LyyycCz8svv8ztt9/OX//6V9auXct7773HvffeS0cDmZ566inS0tJYs2YNa9as4YknnmD37t3cddddPPPMMwBUVVWxatUqPve5z510Xf0scPRze5wWQF5GUqAs1u3iP784lbLjDfzize0nfe9P9xwFYMm3z2PDTy/j7vNHs3p3BUdqGrtXaWP6q6rSrpWHYebMmRw+fJj9+/ezfv16Bg4cyNChQ/nRj37EtGnTuOSSS9i3bx+HDh1q9x5vvfUWzz33HDNmzODss8+moqKCnTt3csEFF7Bz507Kysr405/+xHXXXUdMTPdT25Yc7+d2l7dtcQBMz03njjmjeHrlbt7bfpi8wcnkZSRx97wxjBicFOpWbazdW0lqQgyThqbicgkLpg/n8Q+KeGfrIW7Iz+38BsacbtJynG6qEOXdcP311/PKK69w8OBBbrzxRp5//nnKysr49NNPiY2NJS8vr8MJiqrKb37zGy6//PI2x2677Tb++Mc/8uKLL7Jo0aJu1dPPWhz9XHF5DZkp8STHt/0M8L3LJ/D9KyZw5siBHG/w8OInJTy+YlfY9/5s71FmjBiIy+UbqnfG8FSy0xN5a3P3cifG9FsX3w+xiS3LYhN95d1w44038uKLL/LKK69w/fXXU1VVRVZWFrGxsbz33nvs2RNykdqAyy+/nMcee4ymJl/X9I4dO6ip8X2ovOOOO3j44YcBmDx5crfq6Wctjn5uT0Uto1q1NvwS49x8Y/7YwOu7nlnDhzvLw7rv8fomth86zhVThgbKRITLzhjC86v3Ut3gYUCIYGXMaW3aDb7vf3/A1z2VluMLGv7yk3TGGWdw/PhxsrOzGTZsGAsXLuTzn/88U6dOJT8/n4kTJ3Z4/Ve+8hWKi4uZNWsWqkpmZmYgKT5kyBAmTZrEtdde2606BrP/8/u53RU1XDghvEUc543L4O/bDrO3orbT7qr1JVWowqwRA1uUX3HGUBatLOb97WV8btqwk663Mf3WtBu6HShC2bhxY+DnjIwMPvroo5DnVVdXA759hvxzOFwuFw899BAPPfRQm/Nra2vZuXMnN998c4/V1bqq+rFqZyjuyHZaHK3NG+8LMCsKWy4zv3TjAf7ppXUtRm2s3XsUEZgxIr3Fufl5gxicHMcy664yps975513mDRpEt/61rdIS0vrsftai6Mf2+MMxR2VEV7gGJ2RTHZ6Iit2lLPw7JGAL6n2q7e2s6ushhvyczl3zGDAFzjGZQ0gNaHlaplul3DJpCEs2XiABk8z8THuHnxHxpiedMkll3SaHzkZ1uLox4rLnaG4YbY4RIR54zJYuascT7MXgDXFR9lV5gtAf1zt+wfm9Spr9xxt003ld8WUoVQ3eFi1qyLkcWPM6c0CRz/mn/w3MszhtQDzxmVyvN7D+tIqAP70yV5SEmJYePYIlm06yOFj9RSVV3Os3tNu4JgzdjAD4mNsdJU5bUTDKuEd6er7t8DRjxWX15DVzlDc9swdOxgRWLGzjKM1jSzZeIAvzMzmK/NG4/EqL60pYe2eSgBmjUwPeY/4GDcXTszizU0HqW9q7pH3YkxvSUhIoKKiImqDh38/joSE8BdFtRxHP1ZcUUNemPkNv/SkOKblpLNiZzkpCbE0erzcdNYIRmUkM29cBn/6ZC9zx2aQmhDD6IwB7d7nprNyeX39fv624QBfOrN7k5+M6U05OTmUlpZSVlbW+cmnKf8OgOGywNGP7S6v5eKJWV2+7vxxGfxu+S7KjjcwIzedycNTAVh49ki+/sdPeXXdPuaMyQhM/AtlzpjBjMsawDOrdnPdrOyo38/A9F+xsbFh73xnfCLaVSUiV4jIdhEpFJH7Qhy/Q0TKRGSd8/WVoGO3i8hO5+v2oPIzRWSjc89HJEqfWNUNHsqrGxiZEX5+w2/euEyavcreI7XcMntEoPySSVkMTU2gqVnbzW/4iQi3z8lj075jrN17tMt1MMb0XxELHCLiBh4FrgQmAzeLSKj57i+p6gzn60nn2kHAT4CzgdnAT0TE/yR7DPgqMM75uiJS76EvK3bWqGpv1nhHZo5IJznOzYD4GK6efmISX4zbxc1OIGkvvxHsCzOzSUmIYdHK4kBZXWMzT64ooqK6ocv1Msb0D5HsqpoNFKpqEYCIvAhcA2wJ49rLgbdV9Yhz7dvAFSKyHEhV1Y+d8ueAa4E3er76fVtgOfUu5jjAt3ruPReNIynO3WaL2bvmjSI9KZY5YzI6vU9yfAw35ueyaFUxB6vqSYh1cdezBXy65yiFh6v5z+umdbluxpi+L5JdVdlA8DKSpU5Za9eJyAYReUVE/EuutndttvNzZ/dERO4WkQIRKTgdk17+5dS7MhQ32D/OH8Ptc/LalA+Ij+H2OXm4O8hvBLvt3Dy8qvz32zu4/vcfsbG0ivyRA/nz2lIOVrW/mmewQ8fq+c83tlF23FopxvQHvT0c93UgT1WnAW8Dz/bUjVX1cVXNV9X8zMzw1nLqa3YeOs5/vbkt5DDB3eU1DEmNb9NiONVGDE7i4olZvFRQwsGqep798mz++8YZeBWeXFHU6fUf7argc4+s4Pfv7+I37+48BTU2xnRXJAPHPiB404YcpyxAVStU1f8x80ngzE6u3ef83O49TyevrC3ld8t3cTjEJ/Hi8pqwZ4xH2ncuHs/Zowbx4tfO4dwxg8kdlMSC6cN54ZO9HG1n0yevV/nd8kIWPvkxqYmxXDA+k/8rKKWy1jaJMqavi2TgWAOME5FRIhIH3AQsDj5BRIKXV10AbHV+XgZcJiIDnaT4ZcAyVT0AHBORc5zRVLcB3d9At4/addi3Cua+yro2x4oravtM4Jiak8ZLXzuXM4afWETtH+ePobaxmWdWFYe85nfLC/mvN7dz5dRhLL7nPH541UTqmpp5fvXeU1RrY8zJiljgUFUPcA++ILAVeFlVN4vIAyKywDnt2yKyWUTWA98G7nCuPQI8iC/4rAEe8CfKgW/ga50UArs4jRPj/jWk9rcKHLWNvqG44e7k1xvGD0nh0slDeGZVMdUNnhbHCg9X88jfC/nc1GH89uaZDIiPYeLQVOaNy+CZVcU0eGw2ujF9WURzHKq6VFXHq+oYVf13p+x+VV3s/PxDVT1DVaer6oWqui3o2qdVdazztSiovEBVpzj3vEdP03UCGjzNgdVvWweOfUd9r3MH9d3AAfCN+WOoqmvi0fcKA3kar1f54V82kBjn5qcLzmgxcfCr80ZTdryB19cf6K0qG2PC0NvJcdOOPRW1eJ2QuL+y5eikUidw5AxMbH1ZnzJzxEC+MDObx5bv4vuvbKDB08wLn+xlTfFR/vVzk8hMiW9x/rxxGUwcmsKTK4qidt0gY/oDW3Kkjyp08huxbmnT4ig56huK29cDB8Cvrp9O7qAkHvn7TnYermbX4Wrmjh0ccn0rEeGu80bxvVc28GFhOfPG9c/RcMac7qzF0Uf5E+MzRwxkf1XLwFF6tI74GBeZA+JDXdqnuFzCP186nt8tnMX2g8dp8np56AtT213basGM4QxMiuWvn/XMYLk9FTW8XFDS+YnGmLBZi6OPKiyrJjs9kbFZA3hzU8t9L0qP1pI9MLFfLSx41dRhTBqWyvH6pg63uo2PcXPmyEGs21vZI7/30fcKebmglEsnDWFgclyP3NOYaGctjj5qV1k1Y7IGkJ2eyJGaRuoaT4w0Kj1aR87Avp0YD2VURjLTcjpfA2vWyHSKymvanQMSLlVlZaFvl8LN+491617GmBMscERQo8fbZihqOLxeZdfhGsZkJjMszbe5yoGg7ipf4Oj7+Y2T5V+Z97OS7q26W3KkLjAHZtP+qm7XyxjjY4Ejgh5aupUFv/mQZm/XRggdOFZPXVMzY7MGMDzdFyD8I6tqGjwcqWk8rQPHtJw03C4J7ER4slbuKgcgMdbNpn0WOIzpKRY4Iqj0aC1F5TV8sKNriyz6R1SNyfR1VcGJuRz+T9D9sasqXElxMUwaltLtfT5W7aogKyWeC8ZnWuAwpgdZ4IggfzfV86v3dOk6/4iqsVkDGJKagMiJgFHaj4bidsesEQNZX1LZ5daan6ry0a5y5owZzNScNIorajlW39TDtTQmOlngiKCaBl9C+91th9vMxehIYVk1aYmxDE6OI84ZduvPcfSXyX/dNWvEQGoam9l+8PhJXb/jUDXl1Y3MGZvBGc7WuFssQW5Mj7DAEUE1DR6m56ajwItrwp9LsOtwNWMykwPDbYenJwZyHCVHavvNHI7u8CfIT7a7amWhL78xZ8zgwOKL1l1lTM+wwBFB1Q0eJg1N4fxxmby0Zi+eZm9Y1+0qq2Zs1oDA6+z0xECLpfRoXb+bw3EycgclkjEg7qQDx6pdFYwcnETOwCQyU+IZmppggcOYHmKBI4JqGjwkx8dwy9kjOHSsgXe3He70msraRsqrGxmTeSJwDE9PYF9lHarab+dwdJWIMHPEQD47iYmAnmYvq4sqmDNmcKBsSnYqm6yrypgeYYEjQrxepaaxmeT4GC6emMWQ1Piw9prwL6Ue3OIYnp5Ig8fLkZpGSo/Wknua5zf8Zo0YyO7yGo50cSLgpv3HON7gabFv+hnD09hVVk1tY9fn1RhjWrLAESE1zgNqQLybGLeLG/Nz+WBnWWBUVHt2BQ3F9RuW5gsUOw9Xc7S2KSpaHACzRvhmmX/Wxe4qf37j3KAWx9TsNFRh6wFrdRjTXRY4IsQ/ompAfCwA1+fnogqvdrJ4366yauLcrhZ7bfjncqzZ7dvL6nQfUeU3LSedGJd0Oc/xcVEFE4akkBE0gGBKti9BvrHU8hzGdFdEA4eIXCEi20WkUETu6+C860RERSTfeR0nIotEZKOIrBeR+UHnLnfuuc75yorkezhZ/jkcyfFuwLfp0uxRg/jz2n0d7jWxq6yaURnJuF0nkt/D033LjnxSHF2BIzHOzaRhqbyx8SC7y2vCukZV2bL/GNNz01qUD0mNJ2NAnOU5jOkBEQscIuIGHgWuBCYDN4vI5BDnpQDfAVYHFX8VQFWnApcCvxKR4LouVNUZzlfnGedeUNPg76o6sQDxl2blsLu8hs9K2k/4FpXXMCqj5eqxg5LjiI9x8eke3yfvaOmqAvjOxeMoO97A5Q9/wKPvFdLo6XhkWtnxBipqGpk0LLVFuYhwxvA0G1llTA+IZItjNlCoqkWq2gi8CFwT4rwHgZ8DwdvcTQbeBXACQyWQH8G69riaQIvjROC4cupQEmJd/PnT0pDXeJq97K2oZVRmy8AhIgxPT6S2sZn4GBcZA6JnefBLJg/hnXsv4JJJWfxi2Xa+8LuV1De1vyf5VmfC4MShqW2OTclOZefh6g6vN8Z0LpKBIxsInvVW6pQFiMgsIFdVl7S6dj2wQERiRGQUcCaQG3R8kdNN9WPpoxMajodocaQkxHL5GUN5ff3+kA+vfZV1eLzKqBD7Vfi7q3KiYA5Ha0NSE/jdwjP59Q3T2bz/WId5In/ye/KwtoFjanYazV7lbxtsT3NjuqPXkuNO19OvgXtDHH4aX6ApAB4GVgH+J+1CpwtrnvN1azv3v1tECkSkoKysa4sM9oRQLQ6AL87K4Vi9J+ScjiKnH791iwNguDOyKpq6qVr7wsxspmSn8viKIrztrGG19cAxhqclkJYU2+bY/AlZnJU3kB/+ZQPLt/fJHk5j+oVIBo59tGwl5DhlfinAFGC5iBQD5wCLRSRfVT2q+k9ODuMaIB3YAaCq+5zvx4EX8HWJtaGqj6tqvqrmZ2ae+r2rQ+U4AM4bm0FWSnzI7qpif+DICNXi8AeO6EiMhyIifO38MRSV1fDO1kMhz9l64BgTQ7Q2ABJi3Tx5+1mMy0rh63/8lAJnsIExpmsiGTjWAONEZJSIxAE3AYv9B1W1SlUzVDVPVfOAj4EFqlogIkkikgwgIpcCHlXd4nRdZTjlscDVwKYIvoeTVh0YjtsycLhdwhdmZrN8Rxnl1Q0tju0uryElPobBIbY4zU63FgfAlVOGkjsokT98UNTmWIOnmV1lNUwaltLu9WmJsTz75dkMS0vkzmfWUHj45BZRNCaaRSxwqKoHuAdYBmwFXlbVzSLygIgs6OTyLGCtiGwFfsCJ7qh4YJmIbADW4WvBPBGRN9BNNQ0eXAIJsW3/xNfMyKbZq226q3aX1zAqaHHDYMOcHEd2FLc4AGLcLr5y3mg+3XO0TYth56Fqmr3aZkRVa5kp8fzvXbNp9Hj50yfhLz5pjPGJ6fyUk6eqS4Glrcrub+fc+UE/FwMTQpxTgy9R3udVO+tUhQoCE4emkBIfw/qSSm7IP9Gbt7u8JrAqbGtn5Q3imxeO4cIJp77bra+5Pj+Hh9/Zwe/fL+LJvEGBcn9ivLPAAb6W29TsNNZ3MDTaGBOazRyPkOoGT5tuKj+XS5iWm8a6oIdWg6eZfZV1IfMb4Ouf/97lE0lJaJv0jTZJcTHcdm4e72w91KKraeuB4yTEusgLMSotlOm56WzaX0VTmKsWG2N8LHB0U6PHyzefXxvY7tWvpoPAATAjN51tB48HhuXurahFNXRi3LR127kjiYtxsWhlcaBs28FjTBiS0mLWfUem56ZT3+Q96c2ijIlWFji66UBVHUs2HuDDnS2H/Pq7qtozPSedZq8GZjLv7mBElWlr8IB4rp0xnL+s3UdlbSOqytYDx8LqpvKbmetbRHF9qXVXGdMVFji6qb7J181xtLblftbhtDiAQHeVP3DkWeAI251zR1HX1MyLa0o4dKyBo7VNTBza/oiq1nIGJjIoOY51J7HnhzHRzAJHNzV4fF1NR2tb7hlR09AcWOAwlKzUBIanJbC+9ESLY3ByHGmJlsMI16RhqZw7ejDPrSpmo9Ny60qLQ0SYkZveYYujqdnLkg0HOl0jq9mrtpSJ6XUf7Cjj5TUlHS6k2hMscHRTgyd0i6Ozrirw9bGvK/EtXLg7xOKGpnN3zs1jf1U9v313J0C7k//aMz0nnZ2Hqzle3xTy+Kuf7eObL6zlG8+v7TB4/HTxZq56ZEXE/4c1/Z+qUtFqDldP3ffHr23i+3/ewH1/3hjRQR8WOLrJ/ynzaKtd6joaVeU3IzedkiN1VFQ3sLu8xrqpTsLFk4YwYlAS60uryE5P7HKLbXqub4Onje2smvtZSSUxLuGdrYfaDR4V1Q28VFBCUVkNOw5Vh7iLMSf8cfVezn7o7+w81LODMnYermZPRS2zRqTzUkEJdyz6hKq60B+IussCRzc1BHIcJwKHqnaa4wBfiwNg1a4KDh9vsBbHSXC7hNvn5AF0OGO8Pf5c0/qS0IFjfUkl54wezAPXnNFu8Hhh9d5A2Qc7Tv26aKb/qG308D/v7MTjVZ4OGhHYE97e4luG57F/OJNffGkaq4uO8KXHVnH4WH0nV3adBY5uCnRVBbU4GjxePF7ttKtqanYaLoHX1vmW8LLAcXJuyM9hcHIcZwVNBgxXelIceYOTAl2Gweoam9l28DjTc9O47dy8QPD42ZItgXMaPV7+9+M9zBuXwfghA3jfAofpwLOr9lBe3cCM3HT+sra0TU9Fd7y15RDTc9IYkprA9fm5PPfl2YzJHEB6Us9vw2CBo5tOJMdPNAnbW+CwteT4GMYPSWH5dt/DxgLHyUlJiGXFDy7kq/NGn9T103PTQ7Y4Nu+votmrzMj1zea/7dw8vjx3FM99tIf3nOVi3th0gMPHG/jy3FGcPy6TT3YfodbZb96YYMfqm/j9+7u4cEIm//WlaTR4vLzwyd4euffhY/WsL6nk0slDAmVzxmbw+1vPJC6m5x/zFji6yT8ct66pOZDv8O833lmLA3zJWY+zRHi4M55NW0lxMbjCnPjX2ozcdA4eq+dgVcsmvX+o9PScE9vQfv+KCUwcmsL3XllPeXUDT68sZnRGMheMz+SCCZk0NntZXWSr7pq2nlyxm6q6Ju69bALjh6Qwb1wGz31U3CNJ7He2+j7IXDp5aLfvFQ4LHN3kb3HAiTxHdaDF0f5wXL8ZI3x97MPSEkiM6/x80/Omt5pT47eupJLhaQlkpSYEyhJi3Tx80wyO1Xu49alPWF9SyR1z83C5hLPyBpEQ67LuKtPGkZpGnlpRxFVThzIl2/dB5M65eRw61sDSjd3fWOztLQfJHZTI+CEDun2vcFjg6KaGoETpkZrWgaPzET7Tc3wPLeum6j2Th6US65Y2gWN9aWUgsAebODSVH1wxka0HjpGSEMN1s3IAX1A5Z/RgS5CbNp76sIi6pmb++dLxgbL547MYlZHcYtmck1HT4GHlrgounTT0lO0OaoGjm4InfVU6eY4Tu/913oIYP2QAKU6uw/SOhFg3U7LTeG/b4cA8jIrqBkqO1AUCe2t3zsnj1nNGct+VE1t0SZ4/LpOi8hpKjtSekrqb/uGNjQeZOzaDsVkn/j93uYQ75+axrqSST/ecfPfmBzvKaPR4W+Q3Is0CRzd13OLoPMcR43bx52/M4TsXj4tMBU1Ybpk9gu2HjrNiZzlwYv0q/3Dd1lwu4cFrp7Dw7JEtyi9wlr237irjV1xeQ1F5DRdPzGpz7LpZvhGBv357x0nf/+0th0hLjOWsvNBbMkSCBY5u8s/jAKh0chzt7TfenvFDUhgYYtc/c+osmDGcrJR4Hnd2FlxXUoVLCPRHh2t0RjI5AxOtu8oE+Ddsu2hi2xZBcnwM37hwLCsLK1hZWN7uPcqrG3h+9Z4WOVWADaWVLNt8kIsmZhHjPnWP84j+JhG5QkS2i0ihiNzXwXnXiYiKSL7zOk5EFonIRhFZLyLzg8490ykvFJFH5FR16rWjwdMcmK18pMbXVVXdxcBhel98jJs7547iw8JyNu2rYn1JJeOHpHT5v6GIcP74TFbtqrB9PgzgCxxjswYwYnDobZ8Xnj2C4WkJ/Ney7e0uWfPvS7by//66iZse/zgw+u/TPUdZ+MRqBibHtcidnAoRCxwi4gYeBa4EJgM3i8jkEOelAN8BVgcVfxVAVacClwK/EhF/XR9zjo9zvq6I1HsIR32TlwHxMaTExwRGVQWG49ooqX7llrNHkBzn5okVRb7EeDvdVJ05f1wm1Q2eNsl2E32qGzys3l3BRSG6qfwSYt1895LxrC+pZNnmQ22O762oZfH6/cwZM5gdB49z9W9W8NSHu7n1qdUMHhDHy187l9xBoYNSpESyxTEbKFTVIlVtBF4Erglx3oPAz4HgQfSTgXcBVPUwUAnki8gwIFVVP1ZfaH4OuDaC76FTDZ5m4mNdDEyOCxqO20RirPuUNh1N96UlxnLT7BG8tm4/lbVNgWG6XXXu6MG4hA67Hkx0+HBnOU3NyoUT2g8cAF+clc2YzGR+9dZ2mr0tWx2//2AXbhH++8YZvHbPXFITY3nwb1sYnp7Iy187l+HpiZF8CyFF8smWDZQEvS51ygJEZBaQq6pLWl27HlggIjEiMgrfPuO5zvWlHd3zVGvweImPcTMwKTYwe7y6odm6qfqpL583KrCD4Mm2ONKSYpmSncaqwoqerJrph97ddoiUhBjyO0lcx7hd/MtlE9HS/HgAACAASURBVNh5uLrFbPKDVfW8UlDKl/JzGJKawNisFF775lx+fPVkXrz7nBZzjE6lXvtI7HQ9/Rq4N8Thp/EFhQLgYWAV0KXNDkTkbhEpEJGCsrLIJSp9gcNpcdScSI6HM/nP9D3Z6YksmD6c1IQYxmWd/GSqOWMy+KzkqC0/EsW8XuW97WWcPz6T2DB6H66YMpQ5YwZz/2ubeGblbgCeWFFEsyr/eMGYwHkpCbHcdd4oMgbER6zunYlk4NiHr5Xgl+OU+aUAU4DlIlIMnAMsFpF8VfWo6j+p6gxVvQZIB3Y41+d0cM8AVX1cVfNVNT8zM7PH3lRr9U3NvsCRFBeU4+h8Lw7Td/37F6bwt2/N61ZX45wxg2lqVj7ZbcuPRKvN+49RdryBizrppvITEZ66/SwunTSEn76+hR+/uokXVu/lmunDT3kOozORDBxrgHEiMkpE4oCbgMX+g6papaoZqpqnqnnAx8ACVS0QkSQRSQYQkUsBj6puUdUDwDEROccZTXUb8FoE30OnGjxeEmLdvsARNI/DAkf/lRQX0+4ImHCdlTeIOLeLVbusuypavbvtMCIwf0L4H1wT49w89g9nctu5I/nfj/dQ19TMP84f0/mFp1jEnm6q6hGRe4BlgBt4WlU3i8gDQIGqLu7g8ixgmYh48bUobg069g3gGSAReMP56jUNTc3Ep8QzMCmWmsZmGjzN1DR6GJLSO32Ppm9IjHMzc0Q6q3a1TJCv2FlGzsAkW2ImCry99SAzctMZ3MUuJbdL+LcFZzBuSAq1DR7G9cFVJSL6sVhVlwJLW5Xd386584N+LgYmtHNeAb4urj6hweMlPtYdmMBXWdtEdb2H0RnW4oh2c8dm8N/v7KCytpH0pDi2HzzOHYvWcNXUYfzm5pm9XT0TQWv3HmXTvmP89PNtZiCERUS49ZyRnZ/YS2y8aDc1NDWT4OQ4wLdCro2qMgBzxw5GFT7aVeHbD/rVTTR7tce3DDV9z6KVxaTEx/Cl/NzOT+6H7OnWTb4Wh4uByf7Z4402qsoAMC0nneQ4Nyt3lVPb2MwnxUfIHZTI7vIamr0aGPZrTi8HqupYuvEAd87JC2u9uv7IWhzddGIeh6/FcaSmkboma3EYiHW7mD1qEO9tK+OhpVuZNSKdb8wfS4PHy76jdb1dPRMh//vRHlSV2+fk9XZVIsYCRzcFD8cFKHUeCKfrJw3TNXPHZrCvso6jtY08eO2UwNyQwjLrrjod1TU288Ine7ls8tA+N4S2J1ng6AZPsxePV0mIdZOe5Ouq8u/DYIHDAJw3LgPw7Vd+xvA0xvoDx+Hq3qyW6Yb1JZU8tHQrb246ENhKwe+vn+2jsraJL583qpdqd2rY060bGp3VT+NjXCTEukmKc1PitDisq8qAb7fAF+8+h5nOToLpSXFkDIizwNGP/frtHS32WxmdmUx2eiKZKfGsLjrClOzUU7o3Rm+wp1s3+PfiiI/xNdwGJsVRetRaHKalc0YPbvF6TOYAdpXV9FJtTHccr2/io10V3DEnj89PH8bHRUdYX1LJoeMNFJXVUFnbyI+vnnTKtnDtLfZ064Z6Z1OV+FjfCKqBybHsOOT7JGktDtOeMVkDWLLhAKp62j9gTjfv7yijsdnLVVOHcebIQZw5clBvV6lXWI6jG/wtjoTYEy2ORmcr2XD2GzfRaWzmAKrqmiivbuz8ZNOnvLX5EIOS4zhz5OndFdUZCxzd4N9vPD7GaXEkndj+NSU+tlfqZPo+S5D3T40eL+9tP8wlk7Kifg6OBY5uqG9yuqqcHMegoH3DrcVh2uMPHLvKLHD0J6t3V3C83sNlk4f2dlV6nQWObmjd4vAPyQXLcZj2DUtLICnObS2OfuatzYdIjHUHhlhHMwsc3dDgJMf9OQ5/iyPGJYFWiDGtiYgzssoCR3+hqry95RDnj88gIdZ6E+zp1g0nhuP6Wxy+wJEcH2OjZUyHxmYNsBZHP7JxXxUHj9VbN5XD+lO64cRwXKfF4QQOm8NhOjM2awB//Wwf1Q0e+/fSB6kqBXuOUlnbRHyMi6UbD+B2CRdNDG83v9Od/YvthsBw3FY5DnsQmM6MyfRt5FRUVs20nPRero0JVl7dwI9f3cQbmw62KJ87dnBg351oF9YTztnGtU5VvSIyHpgIvKGqTRGtXR8XSI63ynHYiCrTmeAhudEcOOoafYuEuvrI8NalGw/wr69uorreww+umMi8cRnUNzVT3+Rl4rC+txNfbwn3o/EHwDwRGQi8hW8/8RuBhR1dJCJXAP+Db+vYJ1X1P9s57zrgFeAsZ8/xWOBJYJZTx+dU9T+cc4uB40Azvr3I88N8Dz2u9XDcgUE5DmM6krd/KSvjf8TwxRXwfg5cfD9Mu6G3q3VKNXuVqx5ZQZzbxSM3z2TC0FPzYP7d8kJU4ZsXjm1R/uHOcr7x/Fqm5aTxq+un98ktW/uKcJPjoqq1wBeB36nq9cAZHV4g4gYeBa4EJgM3i0ibfRRFJAX4DrA6qPh6IF5VpwJnAl8Tkbyg4xeq6ozeDBrQdjhuYpyb+BiXdVWZjm14mZgl3yFbyhEUqkrg9W/Dhpd7u2an1Kpd5ewur6G4oobP//ZDnvuoGFWN6O+sb2rm0XcL+e27hdQ0eFoc+8vaUlITYvi/r59rQaMTYQcOETkXXwtjiVPWWX/MbKBQVYtUtRF4EbgmxHkPAj8H6oPKFEgWkRggEWgEjoVZ11PGPxw3eOjtiEFJDE1L6K0qmf7g7w9AU6uNnJrqfOVR5C9r95GSEMO7/zKfc0cP5v7XNnPv/62P6O9csbOcmsZm6pqaeXvLoUB5fVMzb205xJVThgU+CJr2hRs4vgv8EPirqm4WkdHAe51ckw2UBL0udcoCRGQWkKuqS2jpFaAGOADsBX6pqkecYwq8JSKfisjd7f1yEblbRApEpKCsrKy907qlweMlzt2yf/b5r57NvZdNiMjvM6eJqtKulZ+Gaho8vLnpIFdPG052eiKL7jiLr10wmr+s3cfKwvKI/d43Nh0gNSGG4WkJvLpuX6B8+fbDVDd4+Pz04RH73aeTsAKHqr6vqgtU9eci4gLKVfXb3fnFzn1+Ddwb4vBsfDmM4cAo4F4nWAGcp6qz8HWBfVNEzm+nzo+rar6q5mdmZnanqu3y7/4XLCslwbqqTMfScjosLzx8nNue/uS0niD45qaD1DU1c90s32dJl0v4p0vGk52eyENLt+L19nyXVaPHy9tbDnHp5KFcMzObFTvLKa9uAOD19QcYnBzHOaOjc7XbrgorcIjICyKS6oyu2gRsEZHvdXLZPiA36HWOU+aXAkwBljsJ73OAxSKSD9wCvKmqTap6GFgJ5AOo6j7n+2Hgr/iCTEQsXr+f5dsPt3u8weMNjKgyJmwX3w+xiS2KGiUeLr6ffZV13PrUJ3ywo4wXP9nbSxWMvL98VsqIQUktVplNiHXzL5ePZ/P+Yyxevz+s+zz6XiG3P/0Jb285RHMnwWbVrnKO13u4cspQrp2RTbNXWbLhANUNHv6+7RBXTR1GjNv+fw5HuH+lyap6DLgWeANfK+DWTq5ZA4wTkVEiEgfcBCz2H1TVKlXNUNU8Vc0DPgYWqGoBvu6piyAwFPgcYJuIJDvJdH/5ZfgCWUT89t2dvLSmpN3jDU1e6w81XTftBvj8I5CWCwhHY4fwg6avUJB6Cbc+tZrqBg8Th6bw9pZDEU8W94YDVXWs2lXBF2Zmt1lh4Zrp2ZwxPJVfLNseGLXYnsraRn7z7k5WFpbz1ecKuPCXy3lhdfvB9s1NB0mO8601NWFoChOHpvDqun38fesh6pu81k3VBeEGjlhniOy1wGJn/kaH/6JV1QPcAywDtgIvO/mRB0RkQSe/71FggIhsxheAFqnqBmAI8KGIrAc+AZao6pthvocui49xd/iPt8HTbC0Oc3Km3QD/tAl+Wonn2xt5y3U+N/zhI/YdrePpO85i4TkjKa6oPS2XJXn1s/2owhdnZbc55nIJP7pqEvsq63juo+IO7/PSmhLqm7y8+s25PHrLLAYlx/Gjv27kz5+2zRV5mr28teUQF00aElhr6tqZ2Xy2t5I/vF/E0NQE8qN8j42uCLcz/g9AMbAe+EBERhLGKCdVXQosbVV2fzvnzg/6uRrfkNzW5xQB08Osc7fFx7gCQ25DqbcWh+kBmSnxfOeScfxi2XYe+4dZnJU3iNyBSfz41U28teXQaTU0tKquiT+vLSV/5EBGDk4Oec7csRnMn5DJL5ft4MU1JaTEx5CZEs+PrprE6EzfxMlmr/K/H+/h7FGDmJKdxpTsNK6YMpRbnviYH7+2iRkj0hnjnAvwSfERjtQ0cuWUE2tNLZg+nJ+/uY0tB47xlfNG9ZlJiP1BuMnxR1Q1W1WvUp89wIURrluvS4h1dxg4GjzNgZVxjemOu88fw9ofX8pFE4cAMDQtgWk5aS2GjPZXR2oaeeD1LVz1PyuY8cBbFB6u5qbZIzq85qEvTOXGs3KZNCyV9KQ4Vu8+wjdf+CzQA/DutsOUHq3jjjl5gWvcLuHhm2YQH+PiW0Hngq+bKiHWxfwJJwbKDE9PZHaeLxlu3VRdE+6SI2nATwD/CKb3gQeAqgjVq0+Ij3FxtLb97T0bPF5bPt30mJSElrtGXjppCL96eweHj9WTldo/5wapKve+vI4VO8uZPWoQ3714POeOGczsUR2PXhqensiD104JvP771kPc9WwBP39zGz/5/Bk8u6qYYWkJXDp5SIvrhqUl8svrp3PXswU88LctnD8uk4+LKvjr2n1cMD6TpLiWj7xvXzyOJRsPMC0nrefedBQIt6vqaXxJaP+aCLcCi/DNJD9txcd23FXV0NQcWErdmJ526Rm+wPHO1sPccnbHn9D7qpfWlPDe9jJ+8vnJ3Dl31Enf5+JJQ7hjTh6LVhYzPC2RDwvL+d7lE0KOgrp40hC+PHcUT6/czQur95IY6+bMkQNDzq+aOzaDuWNtY6auCjdwjFHV64Je/5uIrItEhfqShBh3YHZ4KNbiMJE0YUgKIwYl8faWg/0ycJQcqeXBv23h3NGDuf3cvG7f774rJ/JxUQX/vnQrcTEubjort8NzJw5LYUxmMlOz04mz/097VLh/zToROc//QkTmAnUdnH9aiI91Ud/UUY7Da7uBmYgRES6dPISVuyrarKvU13m9yr/833pEhF9cP61HEs8JsW5+c/NMEmPdfGFGNoMHxLd7blyMixvyczlz5CALGhEQbovj68BzTq4D4Chwe2Sq1HfEx7hp6Gg4boiZ48b0pEsnD+GpD3ezZOMBrj8zp9/sLPmHD4pYvfsI/3XdNHIGJvXYfccNSeH9788PrERtekdYgUNV1wPTRSTVeX1MRL4LbIhk5Xpbp8Nxbea4ibD8kQPJGZjI91/ZwBMfFLFg+nCuz8/t8YU0m73K8u2HaWr2kjEgnowB8WQPTCT2JGZS/2VtKT9/cxtXTR3K9fntLK/SDVkp/XOgwOmkS4sqObPH/f4ZeLhnq9O3xDvDcVU15Cc9X4vDuqpM5MS4XSy+5zyWbDzA6+v286u3fXMb3vnnC0iM6/6/Pa9XWbLxAA+/s4NdZTUtjg1NTeCr54/m5tm5bUYjteedLYf43isbmDNmML++YUa/aSGZrunOanyn/b8IfzdUe7kMX7m1OExkDUqO49ZzRnLrOSNZtaucW55YzWPLC/nnbq7CXHKklq8+V8C2g8cZP2QAj94yi5GDkyivbuDwsQb+vLaUB/+2hUffK+RfLpvQaYJ+dVEF33xhLVOGp/L4bfmW/zuNdSdwnH6L6LTSUeDwNHvxeNVaHOaUmjMmgwXTh/P7D4q4Pj+X3EEnlz+ob2rm63/8lP2VdfzPTTO4etpw3K0S2DeclUtB8RH+441t/OurG7lyytB299wuKqvmq88VkDMwkUV3zrYVok9zHX5cFpHjInIsxNdxfEuen9b8wSLUkNwTu/9Zi8OcWj+8aiJuEX62ZEvI481e5dpHV3L2Q+9w2X+/z/W/X8UvWy0aeP9rm9i8/xgP3zSDa2Zktwkafvl5g/jXz03Cq/DBztD72lTVNvGVZwuIcbt45s7ZDGonuJjTR4dPPVVNUdXUEF8pqnraf6QItDhCDMm1wGF6y7C0RO65aCzLNh9iRYiH+YbSStaVVDJ+SAqjM3zrNf32vUI+98gKPtt7lJfW7OXlglK+ddHYwBInHZmWk86g5DiWb2/7uzzNXu7501pKjtby+38486RbQKZ/Oe0f/t0R32GLw1dm/bimN9x13iheWlPCv72+hWXfPb9Fi2H59jJE4H9umhn49L9iZxk/eGUD1z22CrdLmDcug+9eMj6s3+V2CfPHZ/Le9sM0e7XF73po6TZW7Czn59dN7XQZEXP6sI/LHUhwWhOhJgH6y2w4rukNCbFu/vnS8RQeruaT3UdaHHt/RxnTnVaC37xxmbz5T+dzQ34uE4am8D83zWy3eyqU+ROzOFrbxPrSykDZ+pJKnl65mzvm5HHjWf1vZrs5efbU60A4LQ5LjpvecvkZQ0mKc7N4/YmNNY/UNLK+tLLFKrB+qQmx/Od10/jbt+Z1OQ9x/rgMXALvbTuxI+bv399FakIM914WXsvFnD4scHSgwxyHU2bDcU1vSYxzc/kZQ1m68WDgg8yKnWWowgXj2waO7khPiuPMkQN5z9lKeVdZNW9uPsit545ss6qvOf1F9KknIleIyHYRKRSR+zo47zoRUWe/cUQkVkSeFZGNIrJVRH7Y1Xv2hBOjqjpKjluLw/SeBTOGU1XXxAc7ygF4f3sZA5NimZaT3uO/a/6ELDbtO8bhY/U88UERcW4Xd8w5+RVvTf8VscAhIm58W8BeCUwGbhaRySHOSwG+A6wOKr4eiFfVqcCZwNdEJC/ce/aU+ECOo21Xlb/MRlWZ3nTe2AwGJ8fx6rp9eL3K+zvKOH98ZpfyF+G6aGIW4Fsq/S9r93F9fg6ZKe0vNGhOX5F86s0GClW1SFUbgReBa0Kc9yDwc6A+qEyBZBGJARKBRnxb1YZ7zx4RPAGwNWtxmL4g1u3ic9OG8c6WQ3y8u4KKmsYe76bymzg0hWFpCTz89514vF7unjcmIr/H9H2RDBzZQEnQ61KnLEBEZgG5qrqk1bWvADXAAWAv8EtVPRLOPXtSeMNxrcVhetc1M4bT4PHy08WbATg/QoFDRJg/IYtmr/K5acMZMdjmbESrXnvqiYgL+DVwb4jDs4FmfLPTRwH3isjoLt7/bhEpEJGCsrLQM147E9ZwXGtxmF42a4RvBd0dh6qZlpNGRgf7VHTX1dOGERfj4h8vsNZGNItk4NgHBG/RleOU+aUAU4DlIlIMnAMsdhLktwBvqmqTqh4GVgL5YdwzQFUfV9V8Vc3PzDy5T2BhDce1FofpZSLCgum+FYAi1U3lN3dsBht/ehmTh6dG9PeYvi2ST701wDgRGSUiccBNwGL/QVWtUtUMVc1T1TzgY2CBqhbg6566CEBEkvEFlW2d3bOnhTMc15Ljpi+4IT+XkYOT+Pz0yC8hZ61sE7ElR1TVIyL3AMsAN/C0qm4WkQeAAlXt6IH/KLBIRDbjW759kapuAAh1z0i9h1i3C7dLOkyO25Ijpi/Iy0jm/e9d2NvVMFEiomtVqepSYGmrsvvbOXd+0M/V+IbkhnXPSIqPcXU4HDfuJHZIM8aY/syeep1ob/vYBo+XOLcLVwTGyxtjTF9mgaMTCbHudpPjlt8wxkQje/J1wtdVFbrFEW/5DWNMFLLA0Yn4mNAtjvoma3EYY6KTPfk6kRDbfo7D5nAYY6KRPfk6ER/jDjmqqqHJS4KNZzfGRCELHJ2Ib7fF0WwtDmNMVLInXyfiY1ztzhy3HIcxJhrZk68T8bFu6tsdjmtdVcaY6GOBoxPttjg8XltS3RgTlezJ1wnfcNxQy6pbi8MYE50scHTCNxw3VFeV5TiMMdHJnnydiI9xt9tVZaOqjDHRyJ58nYiPcdHY7MXr1RblDU3NNo/DGBOVLHB0wr/fRmNzy1ZHvbU4jDFRyp58nYgP7Dt+Is/hafbS7FVLjhtjopIFjk74WxXBI6v8P1ty3BgTjSL65BORK0Rku4gUish9HZx3nYioiOQ7rxeKyLqgL6+IzHCOLXfu6T+WFcn34M9jBCfI/a0P2zbWGBONIrZ1rIi48e0dfilQCqwRkcWquqXVeSnAd4DV/jJVfR543jk+FXhVVdcFXbZQVQsiVfdg/hZH8Oxxa3EYY6JZJJ98s4FCVS1S1UbgReCaEOc9CPwcqG/nPjc71/aK+BAtjkDgsOS4MSYKRfLJlw2UBL0udcoCRGQWkKuqSzq4z43An1qVLXK6qX4sIiE3/RaRu0WkQEQKysrKTqL6Pv5WRUOLFofTVWXJcWNMFOq1j8wi4gJ+DdzbwTlnA7WquimoeKGqTgXmOV+3hrpWVR9X1XxVzc/MzDzpevrzGMHJcf9WstbiMMZEo0g++fYBuUGvc5wyvxRgCrBcRIqBc4DF/gS54yZatTZUdZ/z/TjwAr4usYgJNRy3wfnZhuMaY6JRJAPHGmCciIwSkTh8QWCx/6CqVqlqhqrmqWoe8DGwwJ/0dlokNxCU3xCRGBHJcH6OBa4GglsjPc6G4xpjTEsRG1Wlqh4RuQdYBriBp1V1s4g8ABSo6uKO78D5QImqFgWVxQPLnKDhBt4BnohA9QMCw3GDchw2HNcYE80iFjgAVHUpsLRV2f3tnDu/1evl+LqvgstqgDN7tJKdCAzHDTWqylocxpgoZE++TpwYjnuixVHb6AEgMc5aHMaY6GOBoxMJIXIclbVNAAxMiuuVOhljTG+ywNGJOHfbrqrKuiZi3UKStTiMMVHIAkcnYtwuYlzSIjleWdtEWmIc7cw9NMaY05oFjjDEx7hadFVV1TWSnhTbizUyxpjeY4EjDAmx7hYTACtrm0hPtMBhjIlOFjjC0LrFUVnbZC0OY0zUssARhvhYd6uuKl+OwxhjopEFjjDEx7hazOOorLUchzEmelngCEN8rJt6p8XR6PFS09hsOQ5jTNSywBGG4BZHVZ1v8p+1OIwx0coCRxgSgnIcVXWNAKTZrHFjTJSywBGG+BhXYDiuf7kR66oyxkQrCxxhiI9x0ei0OAKBw7qqjDFRygJHGIK7qir9OQ4bjmuMiVIWOMLQsqvKn+OwFocxJjpFNHCIyBUisl1ECkXkvg7Ou05E1L/fuIgsFJF1QV9eEZnhHDtTRDY693xETsFKg/ExwcnxJlwCKfER3QPLGGP6rIgFDhFxA48CVwKTgZtFZHKI81KA7wCr/WWq+ryqzlDVGcCtwG5VXeccfgz4KjDO+boiUu/BLz7WFVgd17cybiwul62Ma4yJTpFsccwGClW1SFUbgReBa0Kc9yDwc6C+nfvc7FyLiAwDUlX1Y1VV4Dng2h6veSsJMW6ampVmr1JZ10S6DcU1xkSxSAaObKAk6HWpUxYgIrOAXFVd0sF9bgT+FHTP0o7uGQnxgV0Am6msbSTNhuIaY6JYryXHRcQF/Bq4t4NzzgZqVXXTSdz/bhEpEJGCsrKybtTUlxwHaGjyUlVnK+MaY6JbJAPHPiA36HWOU+aXAkwBlotIMXAOsNifIHfcxInWhv+eOR3cM0BVH1fVfFXNz8zMPOk3Ab7huODbd9z24jDGRLtIBo41wDgRGSUicfiCwGL/QVWtUtUMVc1T1TzgY2CBqhZAoEVyA05+w7nmAHBMRM5xRlPdBrwWwfcAnGhx1Dc1OyvjWo7DGBO9IhY4VNUD3AMsA7YCL6vqZhF5QEQWhHGL84ESVS1qVf4N4EmgENgFvNGD1Q4pPsbX4qhtbOZYvce6qowxUS2ikxFUdSmwtFXZ/e2cO7/V6+X4uq9an1eAr4vrlElwkuNl1Q2ArVNljIluNnM8DP4Wx6Eq34hh66oyxkQzCxxh8A/HPXTMFzhsuRFjTDSzwBGGBH+L47jT4rCuKmNMFLPAEQZ/i+NglZPjsK4qY0wUs8ARBv9w3MPW4jDGGAsc4Qgkx50cR6oFDmNMFLPAEYbAcNzjDaQmxOC2lXGNMVHMAkcY/C0Or1p+wxhjLHCEwZ/jANtr3BhjLHCEweUS4ty+P5UtqW6MiXYWOMLkb3VYV5UxJtpZ4AiTfy6HDcU1xkQ7Cxxh8ifILcdhjIl2FjjC5G9xWI7DGBPtLHCE6USLw3IcxpjoZoEjTIHkuLU4jDFRLqKBQ0SuEJHtIlIoIvd1cN51IqLB+42LyDQR+UhENovIRhFJcMqXO/dc53xlRfI9+Plnj1uOwxgT7SK2A6CIuIFHgUuBUmCNiCxW1S2tzksBvgOsDiqLAf4I3Kqq60VkMNAUdNlC/97kp4olx40xxieSLY7ZQKGqFqlqI/AicE2I8x4Efg7UB5VdBmxQ1fUAqlqhqs0RrGun/F1VaYmW4zDGRLdIBo5soCTodalTFiAis4BcVV3S6trxgIrIMhFZKyLfb3V8kdNN9WMROSUrDibE+locNqrKGBPtei05LiIu4NfAvSEOxwDnAQud718QkYudYwtVdSowz/m6tZ373y0iBSJSUFZW1u36xse4SI5zExdj4wmMMdEtkk/BfUBu0Oscp8wvBZgCLBeRYuAcYLGTIC8FPlDVclWtBZYCswBUdZ/z/TjwAr4usTZU9XFVzVfV/MzMzG6/mfPHZ/LFWTndvo8xxvR3kQwca4BxIjJKROKAm4DF/oOqWqWqGaqap6p5wMfAAifpvQyYKiJJTqL8AmCLiMSISAaAiMQCVwObIvgeAj4/fTgPXjvlVPwqY4zp0yI2qkpVPSJyD74g4AaeVtXNIvIAUKCqizu49qiI/Bpf8FFgqaouEZFkYJkTNNzAO8ATkXoPxhhj2hJV7e06RFx+fr4WFJzS0bvGGNPvicinqprfutwyvcYYY7rEAocxxpguscBhjDGmSyxwGGOM6RILHMYYY7rEJbjhnQAAB0JJREFUAocxxpguiYrhuCJSBuxxXqYBVR383Pp7BlDehV8XfM9wjrUuC7d+/rLYLtbvVNaxr/8NT7Z+/aGO/bl+3aljR2X2N+z633CkqrZdekNVo+oLeLyjn0N8LzjZ+4dzrHVZuPXz/9zV+p3KOvb1v+HJ1q8/1LE/1687deykrvY37OLfsL2vaOyqer2Tn1t/7879wznWuizc+nX2uzpyqup4utavs2v7Qh37c/3aOx5OHTsr6wr7G7YjKrqqukNECjTEzMm+oq/XD/p+Hft6/aDv17Gv1w/6fh37ev2CRWOLo6se7+0KdKKv1w/6fh37ev2g79exr9cP+n4d+3r9AqzFYYwxpkusxWGMMaZLLHAYY4zpEgscxhhjusQCRzeIyDwR+b2IPCkiq3q7Pq2JiEtE/l1EfiMit/d2fUIRkfkissL5O87v7fqEIiLJzv71V/d2XUIRkUnO3+8VEfnH3q5PayJyrYg8ISIvichlvV2fUERktIg8JSKv9HZd/Jx/d886f7uFvV2fYFEbOETkaRE5LCKbWpVfISLbRaRQRO7r6B6qukJVvw78DXi2r9UPuAbfXu9N+PZx71E9VEcFqoGEnq5jD9UP4AfAyz1Zt56so6pudf4d3gDM7YP1e1VVvwp8HbixJ+vXg3UsUtW7erpurXWxrl8EXnH+dgsiXbcu6cpMxdPpCzgfmAVsCipzA7uA0UAcsB6YDEzFFxyCv7KCrnsZSOlr9QPuA77mXPtKX/wbAi7nuiHA832wfpcCNwF3AFf3xb+hc80C4A3glr5YP+e6XwGz+urfMFL/n3Sjrj8EZjjnvBDJenX1K2J7jvd1qvqBiOS1Kp4NFKpqEYCIvAhco6r/AYTsphCREUCVqh7va/UTkVKg0XnZ3JP166k6BjkKxPe1+jndZ8n4/keuE5GlqurtS3V07rMYWCwiS4AX+lL9RESA/wTeUNW1PVW3nqzjqdKVuuJrgecA6+hjvUNRGzjakQ2UBL0uBc7u5Jq7gEURq1FLXa3fX4DfiMg84INIVixIl+ooIl8ELgfSgd9GtmpAF+unqv8PQETuAMp7Mmh0oKt/w/n4ujXigaURrZlPV/8dfgu4BEgTkbGq+vtIVs7R1b/hYODfgZki8kMnwJwq7dX1EeC3IvI5urc8To+zwNFNqvqT3q5De1S1Fl9g67NU9S/4AlyfpqrP9HYd2qOqy4HlvVyNdqnqI/gegn2Wqlbgy8H0GapaA9zZ2/UIpU81f/qAfUBu0Oscp6yv6Ov1+//t3U+IVWUYx/HvLyhEJsJFRNQiHQQRQYcwYiJx0SYxmE1EtHAhuggKicxFRC5cBEWFUWSLCCT8Vy2GAgUXgn/QZGhmIWqRbgRDWmROxCziafE+wz1cZu6cA1fvufj7wGVmzjnvPb+zmHnmPefyPtD+jG3PB+3P2PZ8MBwZ5w1TVsCFo9tFYLWklZIeojwUnRxwpqq254P2Z2x7Pmh/xrbng+HIOG+YshaDfjo/qBdwCLhJ56Oq23P7FuBXyqcc3nW+4c3Y9nzDkLHt+YYl4zBm7fXyIodmZtaIb1WZmVkjLhxmZtaIC4eZmTXiwmFmZo24cJiZWSMuHGZm1ogLh92XJM3e4/P1pV+LSv+S25KmJV2R9FGNMROS1vbj/GbgwmHWF5J6rvsWEeN9PN3piNgAjAFbJS3Vg2OCsrqvWV+4cJglSaOSjkuaUulKuCa3vyTpgqRfJJ2U9Fhu3yvpoKSzwMH8+WtJpyRdk/Rm5b1n8+vm3P9dzhi+zWXHkbQlt01J2i/px155I+JfypLbT+T4HZIuSpqR9L2k5ZLGKb06PsxZyuhi12lWlwuHWcdXwBsR8TTwNvBFbj8DPBsRY8Bh4J3KmLXACxHxav68hrJM/DPA+5IeXOA8Y8CuHLsKeE7SMuAA8GKe/9GlwkpaAayms2T+DxGxMSLWA5cpy1mco6x7tDsiNkTE7z2u06wWL6tuBkgaAcaBYzkBgE5jqSeBI5Iep3Rou14ZOpn/+c/7KSLmgDlJtyidDbtb4v4cETfyvNPAU5T2udciYv69DwE7F4n7vKQZStH4NCL+yO3rJO2j9DYZAU40vE6zWlw4zIoHgL/y2UG3z4CPI2Iymybtrez7p+vYucr3/7Hw71idY3o5HRFbJa0Ezks6GhHTwDfARETMZOOpzQuM7XWdZrX4VpUZEBF/A9clvQyl3amk9bn7ETr9EbbdpQhXgVWVtqKvLDUgZycfAHty08PAzbw99lrl0Du5b6nrNKvFhcPuV8sl3ai83qL8sd2et4EuUfo+Q5lhHJM0Bfx5N8Lk7a7XgeN5njvA7RpDvwQ2ZcF5D7gAnAWuVI45DOzOh/ujLH6dZrV4WXWzlpA0EhGz+Smrz4HfIuKTQecy6+YZh1l77MiH5Zcot8cODDiP2YI84zAzs0Y84zAzs0ZcOMzMrBEXDjMza8SFw8zMGnHhMDOzRlw4zMyskf8BrMTqH1CWrRoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "7X6SldCj578A",
        "outputId": "8cb340df-19fc-4905-d7fa-b98625462ee4"
      },
      "source": [
        "multi_learn.fit_one_cycle(3, 0.0005)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/3 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>t_accuracy</th>\n",
              "      <th>v_accuracy</th>\n",
              "      <th>tv_accuracy</th>\n",
              "      <th>weighted_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='14' class='' max='293' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      4.78% [14/293 00:41<13:53 0.4880]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PRpDNAVcvDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c4277f-207f-4dd3-ddac-c3b608c1b708"
      },
      "source": [
        "%debug"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m(276)\u001b[0;36mshow_results\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    274 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    275 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 276 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    277 \u001b[0;31m        \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    278 \u001b[0;31m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_decoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> dl\n",
            "ipdb> dl==None\n",
            "True\n",
            "ipdb> self.dls[ds_idx].new(shuffle=shuffle)\n",
            "*** AttributeError: 'MixedDLS' object has no attribute 'new'\n",
            "ipdb> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJqBJRjkWSZZ"
      },
      "source": [
        "pred[0].shape, pred[1].shape, pred[2].shape\n",
        "\n",
        "(torch.Size([64, 2]), torch.Size([64, 133, 400]), torch.Size([64, 133, 400]))\n",
        "\n",
        "targ.shape\n",
        "torch.Size([64])\n",
        "\n",
        "txt_out[0].shape, txt_out[1].shape, txt_out[1].shape\n",
        "(torch.Size([64, 2]), torch.Size([64, 133, 400]), torch.Size([64, 133, 400]))\n",
        "\n",
        "xb[0].shape\n",
        "torch.Size([64, 2])\n",
        "\n",
        "xb[1][0].shape,xb[1][1].shape,xb[1][2].shape,\n",
        "(torch.Size([64, 2]), torch.Size([64, 133, 400]), torch.Size([64, 133, 400]))\n",
        "\n",
        "xb[2].shape\n",
        "torch.Size([64, 2])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkfh_q7kEjYJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "e8fdda48-b683-44cc-8609-562776d189aa"
      },
      "source": [
        "lr=list(tab_learn.lr_find())[0]\n",
        "multi_learn.fit_flat_cos(100, cbs=[EarlyStoppingCallback()], lr=lr)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-89c4e8a5b9b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab_learn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmulti_learn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_flat_cos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStoppingCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tab_learn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J05otx6h_ZWw"
      },
      "source": [
        "# Remove hooks from model (not sure if this is working)\n",
        "multi_learn.model.remove_my_hooks()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lHDQ1OVEKk0"
      },
      "source": [
        "multi_learn.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHDiO71Q_wLR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}